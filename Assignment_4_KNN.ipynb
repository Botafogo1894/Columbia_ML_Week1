{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "# K-Nearest Neighbor (KNN) Project\n",
    "---\n",
    "\n",
    "_Authors: Carleton Smith; W.P.G.Peterson_\n",
    "\n",
    "\n",
    "## Project Guide\n",
    "---\n",
    "- [Project Overview](#project-overview)  \n",
    "- [Part 1: Acquire, Explore, and Preprocess Data](#part1)\n",
    "- [Part 2: Code KNN](#part2)  \n",
    "    -[KNN in sklearn](#sklearn)\n",
    "- [Part 3: Interpret Results](#part3)\n",
    "\n",
    "\n",
    "<a id=\"project-overview\"></a>\n",
    "## Project Overview\n",
    "---\n",
    "#### EXPECTED TIME: 3 HRS  \n",
    "\n",
    "This project has 3 parts:\n",
    "\n",
    "- Part 1: Familiarize yourself with the problem and data\n",
    "- Part 2: Code a KNN Classifier from scratch, evaluate performance, and compare to Scikit-Learn's implementation\n",
    "- Part 3: Interpret results and explain findings.\n",
    "\n",
    "This will include:\n",
    "- Answering simple questions regarding the data  \n",
    "- Manipulating multiple DataFrames  \n",
    "- Coding functions to:  \n",
    "    - Calculate Euclidean distance\n",
    "    - Calculate distance between many pairs of points\n",
    "    - Implement a majority voting system\n",
    "    - Combine the above to create a custom KNN algorithm\n",
    "- Use `KNeighborsClassifier` in `sklearn`  \n",
    "\n",
    "**Motivation**: KNN is a reasonably simple algorithm that is easy to grasp and can be very effective.\n",
    "\n",
    "**Objectives**: By the end of this assignment, you will:\n",
    "- Have a firm understanding of the KNN algorithm\n",
    "- Have practiced running through the data science workflow to solve a problem\n",
    "- Will demonstate how to translate a mathematical algorithm into effective code\n",
    "- Understand common pitfalls when working with distances\n",
    "\n",
    "**Problem**: Classify the type of activity a person is performing based on measurements collected from a smartphone. The activities include:  \n",
    "- Walking\n",
    "- Walking_Upstairs\n",
    "- Walking_Downstairs\n",
    "- Sitting\n",
    "- Standing\n",
    "- Laying\n",
    "\n",
    "\n",
    "**Dataset**: [_Human Activity Recognition Using Smartphones Data Set_](https://archive.ics.uci.edu/ml/datasets/human+activity+recognition+using+smartphones) from the UC Irvine Machine Learning Repositiory.  \n",
    "\n",
    "Dataset description as provided in the original authors:\n",
    "\n",
    "---\n",
    "```\n",
    "The experiments have been carried out with a group of 30 volunteers within an age bracket of 19-48 years. Each person performed six activities (WALKING, WALKING_UPSTAIRS, WALKING_DOWNSTAIRS, SITTING, STANDING, LAYING) wearing a smartphone (Samsung Galaxy S II) on the waist. Using its embedded accelerometer and gyroscope, we captured 3-axial linear acceleration and 3-axial angular velocity at a constant rate of 50Hz. The experiments have been video-recorded to label the data manually. The obtained dataset has been randomly partitioned into two sets, where 70% of the volunteers was selected for generating the training data and 30% the test data. \n",
    "\n",
    "The sensor signals (accelerometer and gyroscope) were pre-processed by applying noise filters and then sampled in fixed-width sliding windows of 2.56 sec and 50% overlap (128 readings/window). The sensor acceleration signal, which has gravitational and body motion components, was separated using a Butterworth low-pass filter into body acceleration and gravity. The gravitational force is assumed to have only low frequency components, therefore a filter with 0.3 Hz cutoff frequency was used. From each window, a vector of features was obtained by calculating variables from the time and frequency domain. See 'features_info.txt' for more details. \n",
    "\n",
    "For each record it is provided:\n",
    "======================================\n",
    "\n",
    "- Triaxial acceleration from the accelerometer (total acceleration) and the estimated body acceleration.\n",
    "- Triaxial Angular velocity from the gyroscope. \n",
    "- A 561-feature vector with time and frequency domain variables. \n",
    "- Its activity label. \n",
    "- An identifier of the subject who carried out the experiment.\n",
    "```\n",
    "\n",
    "Please see the [Data Folder](https://archive.ics.uci.edu/ml/machine-learning-databases/00240/) to explore the data files further.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "<a id=\"part1\"></a>\n",
    "## Part 1: Acquire, Explore, and Preprocess Data\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "### Import Libraries and Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "#### Read in the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "FEATURE_NAMES = '../resource/asnlib/publicdata/features.txt'\n",
    "TRAIN_DATA = '../resource/asnlib/publicdata/X_train.txt'\n",
    "TRAIN_LABELS = '../resource/asnlib/publicdata/y_train.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# read feature names\n",
    "feats = pd.read_table(FEATURE_NAMES, sep='\\n', header=None)\n",
    "\n",
    "# read in training data\n",
    "har_train = pd.read_table(TRAIN_DATA, sep='\\s+', header=None)\n",
    "\n",
    "# read in training labels\n",
    "har_train_labels = pd.read_table(TRAIN_LABELS, sep='\\n', header=None, names=[\"label\"], squeeze = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "### Explore the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "**Print out the first five rows of the training data (`har_train`) -- does everything look okay?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>551</th>\n",
       "      <th>552</th>\n",
       "      <th>553</th>\n",
       "      <th>554</th>\n",
       "      <th>555</th>\n",
       "      <th>556</th>\n",
       "      <th>557</th>\n",
       "      <th>558</th>\n",
       "      <th>559</th>\n",
       "      <th>560</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.288585</td>\n",
       "      <td>-0.020294</td>\n",
       "      <td>-0.132905</td>\n",
       "      <td>-0.995279</td>\n",
       "      <td>-0.983111</td>\n",
       "      <td>-0.913526</td>\n",
       "      <td>-0.995112</td>\n",
       "      <td>-0.983185</td>\n",
       "      <td>-0.923527</td>\n",
       "      <td>-0.934724</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.074323</td>\n",
       "      <td>-0.298676</td>\n",
       "      <td>-0.710304</td>\n",
       "      <td>-0.112754</td>\n",
       "      <td>0.030400</td>\n",
       "      <td>-0.464761</td>\n",
       "      <td>-0.018446</td>\n",
       "      <td>-0.841247</td>\n",
       "      <td>0.179941</td>\n",
       "      <td>-0.058627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.278419</td>\n",
       "      <td>-0.016411</td>\n",
       "      <td>-0.123520</td>\n",
       "      <td>-0.998245</td>\n",
       "      <td>-0.975300</td>\n",
       "      <td>-0.960322</td>\n",
       "      <td>-0.998807</td>\n",
       "      <td>-0.974914</td>\n",
       "      <td>-0.957686</td>\n",
       "      <td>-0.943068</td>\n",
       "      <td>...</td>\n",
       "      <td>0.158075</td>\n",
       "      <td>-0.595051</td>\n",
       "      <td>-0.861499</td>\n",
       "      <td>0.053477</td>\n",
       "      <td>-0.007435</td>\n",
       "      <td>-0.732626</td>\n",
       "      <td>0.703511</td>\n",
       "      <td>-0.844788</td>\n",
       "      <td>0.180289</td>\n",
       "      <td>-0.054317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.279653</td>\n",
       "      <td>-0.019467</td>\n",
       "      <td>-0.113462</td>\n",
       "      <td>-0.995380</td>\n",
       "      <td>-0.967187</td>\n",
       "      <td>-0.978944</td>\n",
       "      <td>-0.996520</td>\n",
       "      <td>-0.963668</td>\n",
       "      <td>-0.977469</td>\n",
       "      <td>-0.938692</td>\n",
       "      <td>...</td>\n",
       "      <td>0.414503</td>\n",
       "      <td>-0.390748</td>\n",
       "      <td>-0.760104</td>\n",
       "      <td>-0.118559</td>\n",
       "      <td>0.177899</td>\n",
       "      <td>0.100699</td>\n",
       "      <td>0.808529</td>\n",
       "      <td>-0.848933</td>\n",
       "      <td>0.180637</td>\n",
       "      <td>-0.049118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.279174</td>\n",
       "      <td>-0.026201</td>\n",
       "      <td>-0.123283</td>\n",
       "      <td>-0.996091</td>\n",
       "      <td>-0.983403</td>\n",
       "      <td>-0.990675</td>\n",
       "      <td>-0.997099</td>\n",
       "      <td>-0.982750</td>\n",
       "      <td>-0.989302</td>\n",
       "      <td>-0.938692</td>\n",
       "      <td>...</td>\n",
       "      <td>0.404573</td>\n",
       "      <td>-0.117290</td>\n",
       "      <td>-0.482845</td>\n",
       "      <td>-0.036788</td>\n",
       "      <td>-0.012892</td>\n",
       "      <td>0.640011</td>\n",
       "      <td>-0.485366</td>\n",
       "      <td>-0.848649</td>\n",
       "      <td>0.181935</td>\n",
       "      <td>-0.047663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.276629</td>\n",
       "      <td>-0.016570</td>\n",
       "      <td>-0.115362</td>\n",
       "      <td>-0.998139</td>\n",
       "      <td>-0.980817</td>\n",
       "      <td>-0.990482</td>\n",
       "      <td>-0.998321</td>\n",
       "      <td>-0.979672</td>\n",
       "      <td>-0.990441</td>\n",
       "      <td>-0.942469</td>\n",
       "      <td>...</td>\n",
       "      <td>0.087753</td>\n",
       "      <td>-0.351471</td>\n",
       "      <td>-0.699205</td>\n",
       "      <td>0.123320</td>\n",
       "      <td>0.122542</td>\n",
       "      <td>0.693578</td>\n",
       "      <td>-0.615971</td>\n",
       "      <td>-0.847865</td>\n",
       "      <td>0.185151</td>\n",
       "      <td>-0.043892</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 561 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0         1         2         3         4         5         6    \\\n",
       "0  0.288585 -0.020294 -0.132905 -0.995279 -0.983111 -0.913526 -0.995112   \n",
       "1  0.278419 -0.016411 -0.123520 -0.998245 -0.975300 -0.960322 -0.998807   \n",
       "2  0.279653 -0.019467 -0.113462 -0.995380 -0.967187 -0.978944 -0.996520   \n",
       "3  0.279174 -0.026201 -0.123283 -0.996091 -0.983403 -0.990675 -0.997099   \n",
       "4  0.276629 -0.016570 -0.115362 -0.998139 -0.980817 -0.990482 -0.998321   \n",
       "\n",
       "        7         8         9      ...          551       552       553  \\\n",
       "0 -0.983185 -0.923527 -0.934724    ...    -0.074323 -0.298676 -0.710304   \n",
       "1 -0.974914 -0.957686 -0.943068    ...     0.158075 -0.595051 -0.861499   \n",
       "2 -0.963668 -0.977469 -0.938692    ...     0.414503 -0.390748 -0.760104   \n",
       "3 -0.982750 -0.989302 -0.938692    ...     0.404573 -0.117290 -0.482845   \n",
       "4 -0.979672 -0.990441 -0.942469    ...     0.087753 -0.351471 -0.699205   \n",
       "\n",
       "        554       555       556       557       558       559       560  \n",
       "0 -0.112754  0.030400 -0.464761 -0.018446 -0.841247  0.179941 -0.058627  \n",
       "1  0.053477 -0.007435 -0.732626  0.703511 -0.844788  0.180289 -0.054317  \n",
       "2 -0.118559  0.177899  0.100699  0.808529 -0.848933  0.180637 -0.049118  \n",
       "3 -0.036788 -0.012892  0.640011 -0.485366 -0.848649  0.181935 -0.047663  \n",
       "4  0.123320  0.122542  0.693578 -0.615971 -0.847865  0.185151 -0.043892  \n",
       "\n",
       "[5 rows x 561 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "har_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "#### Question 1\n",
    "How many rows and columns are in `har_train`?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7352, 561)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "har_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### GRADED\n",
    "\n",
    "### Find out how many rows and columns are in har_train\n",
    "### Assign the tuple of (<rows>, <cols>) to ans1\n",
    "### For your reference you may also want to print out the nubmer of rows and columns\n",
    "\n",
    "### YOUR ANSWER BELOW\n",
    "\n",
    "ans1 = (7352, 561)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "Question 1",
     "locked": true,
     "points": "5",
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "###\n",
    "### AUTOGRADER TEST - DO NOT REMOVE\n",
    "###\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "**Print the first 5 rows of `feats` - the DataFrame of feature names.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1 tBodyAcc-mean()-X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2 tBodyAcc-mean()-Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3 tBodyAcc-mean()-Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4 tBodyAcc-std()-X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5 tBodyAcc-std()-Y</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     0\n",
       "0  1 tBodyAcc-mean()-X\n",
       "1  2 tBodyAcc-mean()-Y\n",
       "2  3 tBodyAcc-mean()-Z\n",
       "3   4 tBodyAcc-std()-X\n",
       "4   5 tBodyAcc-std()-Y"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feats.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "\n",
    "**Change the names of columns via the `.columns` attribute**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "har_train.columns = feats.iloc[:,0]\n",
    "har_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "#### Question 2\n",
    "Are there missing values?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(har_train.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### GRADED\n",
    "### How many \"null\" values are in the `har_train` dataframe\n",
    "### Assign int answer to ans1\n",
    "\n",
    "### YOUR ANSWER BELOW\n",
    "\n",
    "ans1 = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "Question 2",
     "locked": true,
     "points": "5",
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "###\n",
    "### AUTOGRADER TEST - DO NOT REMOVE\n",
    "###\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "**Plot the correlation plot of the first 20 features (`har_train.iloc[:, :20])` with `seaborn`.**\n",
    "\n",
    "- Seaborn: https://seaborn.pydata.org/examples/many_pairwise_correlations.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 792x648 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# seaborn\n",
    "first_twenty = har_train.iloc[:, :20] # pull out first 20 feats\n",
    "corr = first_twenty.corr()  # compute correlation matrix\n",
    "mask = np.zeros_like(corr, dtype=np.bool)  # make mask\n",
    "mask[np.triu_indices_from(mask)] = True  # mask the upper triangle\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(11, 9))  # create a figure and a subplot\n",
    "cmap = sns.diverging_palette(220, 10, as_cmap=True)  # custom color map\n",
    "sns.heatmap(\n",
    "    corr,\n",
    "    mask=mask,\n",
    "    cmap=cmap,\n",
    "    center=0,\n",
    "    linewidth=0.5,\n",
    "    cbar_kws={'shrink': 0.5}\n",
    ");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "#### Question 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### GRADED\n",
    "### In looking at the graphic above:\n",
    "### True or False:\n",
    "### In these first 20 features, some are  highly correlated. e.g. With correlation >0.5 or < -0.5?\n",
    "### Assign boolean answer to ans1\n",
    "\n",
    "### YOUR ANSWER BELOW\n",
    "\n",
    "ans1 = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "Question 3",
     "locked": true,
     "points": "5",
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "###\n",
    "### AUTOGRADER TEST - DO NOT REMOVE\n",
    "###\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "EDA, as was performed (briefly) above is used to develop an idea of potential problems with data. Particularly with modeling, looking for Null / impossible values, and correlated features are important steps to:  \n",
    "1. See if any features will not be useful in models becuase of null values.\n",
    "2. See if any model assumptions are violated by correlated features (such as in linear / logistic regression)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "**Switching to the target variable (`har_train_labels`).**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "#### Question 4\n",
    "Investigate class sizes - are they unbalanced?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6    1407\n",
       "5    1374\n",
       "4    1286\n",
       "1    1226\n",
       "2    1073\n",
       "3     986\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "har_train_labels.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### GRADED\n",
    "### How many times does the majority class appear in our data?\n",
    "### How many times does the minority class appear in our data?\n",
    "### Assign int to ans_maj and ans_min\n",
    "### YOUR ANSWER BELOW\n",
    "\n",
    "ans_maj = 1407\n",
    "ans_min = 986"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "Question 4",
     "locked": true,
     "points": "5",
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "###\n",
    "### AUTOGRADER TEST - DO NOT REMOVE\n",
    "###\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "While the activities are not perfectly represented equally, its fairly close.  \n",
    "A large imbalance in the distribution of the target variable categories can cause machine learning algorithms to train themselves well with the majority class, and perform poorly on the minority class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "**Use the `.describe()` method along with `.groupby()` method to compare the statistics within each activity.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7352, 562)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# concatenate the target variable\n",
    "# give target and observations conventional names\n",
    "y = har_train_labels \n",
    "X = har_train\n",
    "\n",
    "data = pd.concat([X, y], axis=1)\n",
    "data.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>552</th>\n",
       "      <th>553</th>\n",
       "      <th>554</th>\n",
       "      <th>555</th>\n",
       "      <th>556</th>\n",
       "      <th>557</th>\n",
       "      <th>558</th>\n",
       "      <th>559</th>\n",
       "      <th>560</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.288585</td>\n",
       "      <td>-0.020294</td>\n",
       "      <td>-0.132905</td>\n",
       "      <td>-0.995279</td>\n",
       "      <td>-0.983111</td>\n",
       "      <td>-0.913526</td>\n",
       "      <td>-0.995112</td>\n",
       "      <td>-0.983185</td>\n",
       "      <td>-0.923527</td>\n",
       "      <td>-0.934724</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.298676</td>\n",
       "      <td>-0.710304</td>\n",
       "      <td>-0.112754</td>\n",
       "      <td>0.030400</td>\n",
       "      <td>-0.464761</td>\n",
       "      <td>-0.018446</td>\n",
       "      <td>-0.841247</td>\n",
       "      <td>0.179941</td>\n",
       "      <td>-0.058627</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.278419</td>\n",
       "      <td>-0.016411</td>\n",
       "      <td>-0.123520</td>\n",
       "      <td>-0.998245</td>\n",
       "      <td>-0.975300</td>\n",
       "      <td>-0.960322</td>\n",
       "      <td>-0.998807</td>\n",
       "      <td>-0.974914</td>\n",
       "      <td>-0.957686</td>\n",
       "      <td>-0.943068</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.595051</td>\n",
       "      <td>-0.861499</td>\n",
       "      <td>0.053477</td>\n",
       "      <td>-0.007435</td>\n",
       "      <td>-0.732626</td>\n",
       "      <td>0.703511</td>\n",
       "      <td>-0.844788</td>\n",
       "      <td>0.180289</td>\n",
       "      <td>-0.054317</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.279653</td>\n",
       "      <td>-0.019467</td>\n",
       "      <td>-0.113462</td>\n",
       "      <td>-0.995380</td>\n",
       "      <td>-0.967187</td>\n",
       "      <td>-0.978944</td>\n",
       "      <td>-0.996520</td>\n",
       "      <td>-0.963668</td>\n",
       "      <td>-0.977469</td>\n",
       "      <td>-0.938692</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.390748</td>\n",
       "      <td>-0.760104</td>\n",
       "      <td>-0.118559</td>\n",
       "      <td>0.177899</td>\n",
       "      <td>0.100699</td>\n",
       "      <td>0.808529</td>\n",
       "      <td>-0.848933</td>\n",
       "      <td>0.180637</td>\n",
       "      <td>-0.049118</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.279174</td>\n",
       "      <td>-0.026201</td>\n",
       "      <td>-0.123283</td>\n",
       "      <td>-0.996091</td>\n",
       "      <td>-0.983403</td>\n",
       "      <td>-0.990675</td>\n",
       "      <td>-0.997099</td>\n",
       "      <td>-0.982750</td>\n",
       "      <td>-0.989302</td>\n",
       "      <td>-0.938692</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.117290</td>\n",
       "      <td>-0.482845</td>\n",
       "      <td>-0.036788</td>\n",
       "      <td>-0.012892</td>\n",
       "      <td>0.640011</td>\n",
       "      <td>-0.485366</td>\n",
       "      <td>-0.848649</td>\n",
       "      <td>0.181935</td>\n",
       "      <td>-0.047663</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.276629</td>\n",
       "      <td>-0.016570</td>\n",
       "      <td>-0.115362</td>\n",
       "      <td>-0.998139</td>\n",
       "      <td>-0.980817</td>\n",
       "      <td>-0.990482</td>\n",
       "      <td>-0.998321</td>\n",
       "      <td>-0.979672</td>\n",
       "      <td>-0.990441</td>\n",
       "      <td>-0.942469</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.351471</td>\n",
       "      <td>-0.699205</td>\n",
       "      <td>0.123320</td>\n",
       "      <td>0.122542</td>\n",
       "      <td>0.693578</td>\n",
       "      <td>-0.615971</td>\n",
       "      <td>-0.847865</td>\n",
       "      <td>0.185151</td>\n",
       "      <td>-0.043892</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 562 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6  \\\n",
       "0  0.288585 -0.020294 -0.132905 -0.995279 -0.983111 -0.913526 -0.995112   \n",
       "1  0.278419 -0.016411 -0.123520 -0.998245 -0.975300 -0.960322 -0.998807   \n",
       "2  0.279653 -0.019467 -0.113462 -0.995380 -0.967187 -0.978944 -0.996520   \n",
       "3  0.279174 -0.026201 -0.123283 -0.996091 -0.983403 -0.990675 -0.997099   \n",
       "4  0.276629 -0.016570 -0.115362 -0.998139 -0.980817 -0.990482 -0.998321   \n",
       "\n",
       "          7         8         9  ...         552       553       554  \\\n",
       "0 -0.983185 -0.923527 -0.934724  ...   -0.298676 -0.710304 -0.112754   \n",
       "1 -0.974914 -0.957686 -0.943068  ...   -0.595051 -0.861499  0.053477   \n",
       "2 -0.963668 -0.977469 -0.938692  ...   -0.390748 -0.760104 -0.118559   \n",
       "3 -0.982750 -0.989302 -0.938692  ...   -0.117290 -0.482845 -0.036788   \n",
       "4 -0.979672 -0.990441 -0.942469  ...   -0.351471 -0.699205  0.123320   \n",
       "\n",
       "        555       556       557       558       559       560  label  \n",
       "0  0.030400 -0.464761 -0.018446 -0.841247  0.179941 -0.058627      5  \n",
       "1 -0.007435 -0.732626  0.703511 -0.844788  0.180289 -0.054317      5  \n",
       "2  0.177899  0.100699  0.808529 -0.848933  0.180637 -0.049118      5  \n",
       "3 -0.012892  0.640011 -0.485366 -0.848649  0.181935 -0.047663      5  \n",
       "4  0.122542  0.693578 -0.615971 -0.847865  0.185151 -0.043892      5  \n",
       "\n",
       "[5 rows x 562 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>552</th>\n",
       "      <th>553</th>\n",
       "      <th>554</th>\n",
       "      <th>555</th>\n",
       "      <th>556</th>\n",
       "      <th>557</th>\n",
       "      <th>558</th>\n",
       "      <th>559</th>\n",
       "      <th>560</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>7352.000000</td>\n",
       "      <td>7352.000000</td>\n",
       "      <td>7352.000000</td>\n",
       "      <td>7352.000000</td>\n",
       "      <td>7352.000000</td>\n",
       "      <td>7352.000000</td>\n",
       "      <td>7352.000000</td>\n",
       "      <td>7352.000000</td>\n",
       "      <td>7352.000000</td>\n",
       "      <td>7352.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>7352.000000</td>\n",
       "      <td>7352.000000</td>\n",
       "      <td>7352.000000</td>\n",
       "      <td>7352.000000</td>\n",
       "      <td>7352.000000</td>\n",
       "      <td>7352.000000</td>\n",
       "      <td>7352.000000</td>\n",
       "      <td>7352.000000</td>\n",
       "      <td>7352.000000</td>\n",
       "      <td>7352.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.274488</td>\n",
       "      <td>-0.017695</td>\n",
       "      <td>-0.109141</td>\n",
       "      <td>-0.605438</td>\n",
       "      <td>-0.510938</td>\n",
       "      <td>-0.604754</td>\n",
       "      <td>-0.630512</td>\n",
       "      <td>-0.526907</td>\n",
       "      <td>-0.606150</td>\n",
       "      <td>-0.468604</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.307009</td>\n",
       "      <td>-0.625294</td>\n",
       "      <td>0.008684</td>\n",
       "      <td>0.002186</td>\n",
       "      <td>0.008726</td>\n",
       "      <td>-0.005981</td>\n",
       "      <td>-0.489547</td>\n",
       "      <td>0.058593</td>\n",
       "      <td>-0.056515</td>\n",
       "      <td>3.643362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.070261</td>\n",
       "      <td>0.040811</td>\n",
       "      <td>0.056635</td>\n",
       "      <td>0.448734</td>\n",
       "      <td>0.502645</td>\n",
       "      <td>0.418687</td>\n",
       "      <td>0.424073</td>\n",
       "      <td>0.485942</td>\n",
       "      <td>0.414122</td>\n",
       "      <td>0.544547</td>\n",
       "      <td>...</td>\n",
       "      <td>0.321011</td>\n",
       "      <td>0.307584</td>\n",
       "      <td>0.336787</td>\n",
       "      <td>0.448306</td>\n",
       "      <td>0.608303</td>\n",
       "      <td>0.477975</td>\n",
       "      <td>0.511807</td>\n",
       "      <td>0.297480</td>\n",
       "      <td>0.279122</td>\n",
       "      <td>1.744802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-0.999873</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.995357</td>\n",
       "      <td>-0.999765</td>\n",
       "      <td>-0.976580</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.262975</td>\n",
       "      <td>-0.024863</td>\n",
       "      <td>-0.120993</td>\n",
       "      <td>-0.992754</td>\n",
       "      <td>-0.978129</td>\n",
       "      <td>-0.980233</td>\n",
       "      <td>-0.993591</td>\n",
       "      <td>-0.978162</td>\n",
       "      <td>-0.980251</td>\n",
       "      <td>-0.936219</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.542602</td>\n",
       "      <td>-0.845573</td>\n",
       "      <td>-0.121527</td>\n",
       "      <td>-0.289549</td>\n",
       "      <td>-0.482273</td>\n",
       "      <td>-0.376341</td>\n",
       "      <td>-0.812065</td>\n",
       "      <td>-0.017885</td>\n",
       "      <td>-0.143414</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.277193</td>\n",
       "      <td>-0.017219</td>\n",
       "      <td>-0.108676</td>\n",
       "      <td>-0.946196</td>\n",
       "      <td>-0.851897</td>\n",
       "      <td>-0.859365</td>\n",
       "      <td>-0.950709</td>\n",
       "      <td>-0.857328</td>\n",
       "      <td>-0.857143</td>\n",
       "      <td>-0.881637</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.343685</td>\n",
       "      <td>-0.711692</td>\n",
       "      <td>0.009509</td>\n",
       "      <td>0.008943</td>\n",
       "      <td>0.008735</td>\n",
       "      <td>-0.000368</td>\n",
       "      <td>-0.709417</td>\n",
       "      <td>0.182071</td>\n",
       "      <td>0.003181</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.288461</td>\n",
       "      <td>-0.010783</td>\n",
       "      <td>-0.097794</td>\n",
       "      <td>-0.242813</td>\n",
       "      <td>-0.034231</td>\n",
       "      <td>-0.262415</td>\n",
       "      <td>-0.292680</td>\n",
       "      <td>-0.066701</td>\n",
       "      <td>-0.265671</td>\n",
       "      <td>-0.017129</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.126979</td>\n",
       "      <td>-0.503878</td>\n",
       "      <td>0.150865</td>\n",
       "      <td>0.292861</td>\n",
       "      <td>0.506187</td>\n",
       "      <td>0.359368</td>\n",
       "      <td>-0.509079</td>\n",
       "      <td>0.248353</td>\n",
       "      <td>0.107659</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.916238</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.967664</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.989538</td>\n",
       "      <td>0.956845</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.998702</td>\n",
       "      <td>0.996078</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.478157</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 562 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 0            1            2            3            4  \\\n",
       "count  7352.000000  7352.000000  7352.000000  7352.000000  7352.000000   \n",
       "mean      0.274488    -0.017695    -0.109141    -0.605438    -0.510938   \n",
       "std       0.070261     0.040811     0.056635     0.448734     0.502645   \n",
       "min      -1.000000    -1.000000    -1.000000    -1.000000    -0.999873   \n",
       "25%       0.262975    -0.024863    -0.120993    -0.992754    -0.978129   \n",
       "50%       0.277193    -0.017219    -0.108676    -0.946196    -0.851897   \n",
       "75%       0.288461    -0.010783    -0.097794    -0.242813    -0.034231   \n",
       "max       1.000000     1.000000     1.000000     1.000000     0.916238   \n",
       "\n",
       "                 5            6            7            8            9  \\\n",
       "count  7352.000000  7352.000000  7352.000000  7352.000000  7352.000000   \n",
       "mean     -0.604754    -0.630512    -0.526907    -0.606150    -0.468604   \n",
       "std       0.418687     0.424073     0.485942     0.414122     0.544547   \n",
       "min      -1.000000    -1.000000    -1.000000    -1.000000    -1.000000   \n",
       "25%      -0.980233    -0.993591    -0.978162    -0.980251    -0.936219   \n",
       "50%      -0.859365    -0.950709    -0.857328    -0.857143    -0.881637   \n",
       "75%      -0.262415    -0.292680    -0.066701    -0.265671    -0.017129   \n",
       "max       1.000000     1.000000     0.967664     1.000000     1.000000   \n",
       "\n",
       "          ...               552          553          554          555  \\\n",
       "count     ...       7352.000000  7352.000000  7352.000000  7352.000000   \n",
       "mean      ...         -0.307009    -0.625294     0.008684     0.002186   \n",
       "std       ...          0.321011     0.307584     0.336787     0.448306   \n",
       "min       ...         -0.995357    -0.999765    -0.976580    -1.000000   \n",
       "25%       ...         -0.542602    -0.845573    -0.121527    -0.289549   \n",
       "50%       ...         -0.343685    -0.711692     0.009509     0.008943   \n",
       "75%       ...         -0.126979    -0.503878     0.150865     0.292861   \n",
       "max       ...          0.989538     0.956845     1.000000     1.000000   \n",
       "\n",
       "               556          557          558          559          560  \\\n",
       "count  7352.000000  7352.000000  7352.000000  7352.000000  7352.000000   \n",
       "mean      0.008726    -0.005981    -0.489547     0.058593    -0.056515   \n",
       "std       0.608303     0.477975     0.511807     0.297480     0.279122   \n",
       "min      -1.000000    -1.000000    -1.000000    -1.000000    -1.000000   \n",
       "25%      -0.482273    -0.376341    -0.812065    -0.017885    -0.143414   \n",
       "50%       0.008735    -0.000368    -0.709417     0.182071     0.003181   \n",
       "75%       0.506187     0.359368    -0.509079     0.248353     0.107659   \n",
       "max       0.998702     0.996078     1.000000     0.478157     1.000000   \n",
       "\n",
       "             label  \n",
       "count  7352.000000  \n",
       "mean      3.643362  \n",
       "std       1.744802  \n",
       "min       1.000000  \n",
       "25%       2.000000  \n",
       "50%       4.000000  \n",
       "75%       5.000000  \n",
       "max       6.000000  \n",
       "\n",
       "[8 rows x 562 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    },
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">0</th>\n",
       "      <th>count</th>\n",
       "      <td>1226.000000</td>\n",
       "      <td>1073.000000</td>\n",
       "      <td>986.000000</td>\n",
       "      <td>1286.000000</td>\n",
       "      <td>1374.000000</td>\n",
       "      <td>1407.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.276260</td>\n",
       "      <td>0.261930</td>\n",
       "      <td>0.288169</td>\n",
       "      <td>0.273449</td>\n",
       "      <td>0.279294</td>\n",
       "      <td>0.269191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.050353</td>\n",
       "      <td>0.078029</td>\n",
       "      <td>0.095101</td>\n",
       "      <td>0.041998</td>\n",
       "      <td>0.020097</td>\n",
       "      <td>0.101541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.121465</td>\n",
       "      <td>-0.061041</td>\n",
       "      <td>-0.161088</td>\n",
       "      <td>-0.412659</td>\n",
       "      <td>0.111231</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.433256</td>\n",
       "      <td>0.480180</td>\n",
       "      <td>0.617597</td>\n",
       "      <td>0.559135</td>\n",
       "      <td>0.631510</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>median</th>\n",
       "      <td>0.274582</td>\n",
       "      <td>0.266666</td>\n",
       "      <td>0.284955</td>\n",
       "      <td>0.277306</td>\n",
       "      <td>0.277507</td>\n",
       "      <td>0.276946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">1</th>\n",
       "      <th>count</th>\n",
       "      <td>1226.000000</td>\n",
       "      <td>1073.000000</td>\n",
       "      <td>986.000000</td>\n",
       "      <td>1286.000000</td>\n",
       "      <td>1374.000000</td>\n",
       "      <td>1407.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-0.017768</td>\n",
       "      <td>-0.026647</td>\n",
       "      <td>-0.016370</td>\n",
       "      <td>-0.012143</td>\n",
       "      <td>-0.016123</td>\n",
       "      <td>-0.018345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.020880</td>\n",
       "      <td>0.037038</td>\n",
       "      <td>0.027057</td>\n",
       "      <td>0.032421</td>\n",
       "      <td>0.017846</td>\n",
       "      <td>0.073512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-0.127407</td>\n",
       "      <td>-0.183885</td>\n",
       "      <td>-0.094826</td>\n",
       "      <td>-0.121073</td>\n",
       "      <td>-0.116007</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.071488</td>\n",
       "      <td>0.100904</td>\n",
       "      <td>0.099755</td>\n",
       "      <td>0.324130</td>\n",
       "      <td>0.212768</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>median</th>\n",
       "      <td>-0.017867</td>\n",
       "      <td>-0.023000</td>\n",
       "      <td>-0.017714</td>\n",
       "      <td>-0.016457</td>\n",
       "      <td>-0.017097</td>\n",
       "      <td>-0.017364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">2</th>\n",
       "      <th>count</th>\n",
       "      <td>1226.000000</td>\n",
       "      <td>1073.000000</td>\n",
       "      <td>986.000000</td>\n",
       "      <td>1286.000000</td>\n",
       "      <td>1374.000000</td>\n",
       "      <td>1407.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-0.108884</td>\n",
       "      <td>-0.120424</td>\n",
       "      <td>-0.105860</td>\n",
       "      <td>-0.106581</td>\n",
       "      <td>-0.107330</td>\n",
       "      <td>-0.107169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.032436</td>\n",
       "      <td>0.060204</td>\n",
       "      <td>0.050656</td>\n",
       "      <td>0.045323</td>\n",
       "      <td>0.035680</td>\n",
       "      <td>0.089743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-0.285675</td>\n",
       "      <td>-0.403290</td>\n",
       "      <td>-0.289816</td>\n",
       "      <td>-0.560934</td>\n",
       "      <td>-0.509645</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.006195</td>\n",
       "      <td>0.142537</td>\n",
       "      <td>0.091229</td>\n",
       "      <td>0.280939</td>\n",
       "      <td>0.267377</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>median</th>\n",
       "      <td>-0.110424</td>\n",
       "      <td>-0.113635</td>\n",
       "      <td>-0.109039</td>\n",
       "      <td>-0.108125</td>\n",
       "      <td>-0.108771</td>\n",
       "      <td>-0.108104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">3</th>\n",
       "      <th>count</th>\n",
       "      <td>1226.000000</td>\n",
       "      <td>1073.000000</td>\n",
       "      <td>986.000000</td>\n",
       "      <td>1286.000000</td>\n",
       "      <td>1374.000000</td>\n",
       "      <td>1407.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-0.312641</td>\n",
       "      <td>-0.221072</td>\n",
       "      <td>0.139847</td>\n",
       "      <td>-0.983450</td>\n",
       "      <td>-0.985346</td>\n",
       "      <td>-0.959475</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "label               1            2           3            4            5  \\\n",
       "0 count   1226.000000  1073.000000  986.000000  1286.000000  1374.000000   \n",
       "  mean       0.276260     0.261930    0.288169     0.273449     0.279294   \n",
       "  std        0.050353     0.078029    0.095101     0.041998     0.020097   \n",
       "  min        0.121465    -0.061041   -0.161088    -0.412659     0.111231   \n",
       "  max        0.433256     0.480180    0.617597     0.559135     0.631510   \n",
       "  median     0.274582     0.266666    0.284955     0.277306     0.277507   \n",
       "1 count   1226.000000  1073.000000  986.000000  1286.000000  1374.000000   \n",
       "  mean      -0.017768    -0.026647   -0.016370    -0.012143    -0.016123   \n",
       "  std        0.020880     0.037038    0.027057     0.032421     0.017846   \n",
       "  min       -0.127407    -0.183885   -0.094826    -0.121073    -0.116007   \n",
       "  max        0.071488     0.100904    0.099755     0.324130     0.212768   \n",
       "  median    -0.017867    -0.023000   -0.017714    -0.016457    -0.017097   \n",
       "2 count   1226.000000  1073.000000  986.000000  1286.000000  1374.000000   \n",
       "  mean      -0.108884    -0.120424   -0.105860    -0.106581    -0.107330   \n",
       "  std        0.032436     0.060204    0.050656     0.045323     0.035680   \n",
       "  min       -0.285675    -0.403290   -0.289816    -0.560934    -0.509645   \n",
       "  max        0.006195     0.142537    0.091229     0.280939     0.267377   \n",
       "  median    -0.110424    -0.113635   -0.109039    -0.108125    -0.108771   \n",
       "3 count   1226.000000  1073.000000  986.000000  1286.000000  1374.000000   \n",
       "  mean      -0.312641    -0.221072    0.139847    -0.983450    -0.985346   \n",
       "\n",
       "label               6  \n",
       "0 count   1407.000000  \n",
       "  mean       0.269191  \n",
       "  std        0.101541  \n",
       "  min       -1.000000  \n",
       "  max        1.000000  \n",
       "  median     0.276946  \n",
       "1 count   1407.000000  \n",
       "  mean      -0.018345  \n",
       "  std        0.073512  \n",
       "  min       -1.000000  \n",
       "  max        1.000000  \n",
       "  median    -0.017364  \n",
       "2 count   1407.000000  \n",
       "  mean      -0.107169  \n",
       "  std        0.089743  \n",
       "  min       -1.000000  \n",
       "  max        1.000000  \n",
       "  median    -0.108104  \n",
       "3 count   1407.000000  \n",
       "  mean      -0.959475  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# group by the 'label' and show descriptive stats\n",
    "data.groupby('label').agg(['count', 'mean','std','min','max','median']).T.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "**Summary**:  \n",
    "EDA should be tailored to your specific problem - to help develop and understanding of the data for a particular purpose. This is time consuming process when the data are large with many features. It's subject matter experts can guide initial explorations.  \n",
    "\n",
    "The above are examples of just a few of the things EDA should include when starting a project."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "With a feel for the data, now we will aside a \"test\" data-set that will allow us to evaluate out models.  \n",
    "\n",
    "`train_test_split` from `sklearn.model_selection` module provides an easy way to do this.  \n",
    "\n",
    "Setting `test_size=.3` and `random_state=24`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.3, random_state=24)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### GRADED\n",
    "### `test_size = .3` means:\n",
    "\n",
    "### 'a') the final 30% of the data is held out for the test data\n",
    "### 'b') any observations with \".3\" are held out\n",
    "### 'c') a random 30% of the data are held out\n",
    "### 'd') a random 70% of the data are held out\n",
    "### assign character associated with your choice to ans1 as a string\n",
    "\n",
    "### YOUR ANSWER BELOW\n",
    "\n",
    "ans1 = 'c'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "Question 5",
     "locked": true,
     "points": "5",
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "###\n",
    "### AUTOGRADER TEST - DO NOT REMOVE\n",
    "###\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "<a id=\"part2\"></a>\n",
    "## Part 2: Code KNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "Note: The following was adapted from example 2.1.2 in Chapter 2 of [_Machine Learning in Action_ by Peter Harrington](https://www.manning.com/books/machine-learning-in-action)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "Before fitting a KNN model using built in functionality in the `sklearn` package, we will code our own version of KNN.  \n",
    "\n",
    "Given a value (with our movement-data, this \"value\" is better thought of as a vector of values) to be classified, KNN calculates the distance between that value and all other values in the training data-set. Then, the \"`k`\" nearest neighbors are polled as to their \"label\", and the given value is predicted to be of that majority value.  \n",
    "\n",
    "Thus we need to:\n",
    "\n",
    "**Create a function that accepts the following parameters:**  \n",
    "- A single data point to be classified (`input_vector`)\n",
    "- Training data (`X_train`)   \n",
    "- Labels for training data\n",
    "- Value for k (some positive integer)\n",
    "- Optional: Similarity Metric (Euclidean or Cosine)- This exercise will use [Euclidean](https://en.wikipedia.org/wiki/Euclidean_distance) for simplicity.  \n",
    "\n",
    "\n",
    "**Function Signature:**  \n",
    "`def my_knn(input_vector, X_train, y_train, k, [metric])`  \n",
    "\n",
    "**Pseudo Code:**  \n",
    "```\n",
    "for every point in our dataset:\n",
    "    calculate the distance between the current point and input_vector\n",
    "    sort the distances in increasing order\n",
    "    take k items with lowest disances to input_vector\n",
    "    find the majority class among these items\n",
    "    return the majority class label from the k closest neighbors\n",
    "```\n",
    "\n",
    "**Return:**   \n",
    "- The prediction for `input_vector`  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "p1 = (1,2,3,-4,6)\n",
    "p2 = (10,2,32,-2,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "962\n"
     ]
    }
   ],
   "source": [
    "total = 0\n",
    "for i in range(len(p1)):\n",
    "    total += (p2[i] - p1[i])**2\n",
    "    \n",
    "print(total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "answ = total**(1/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31.016124838541646"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dst = distance.euclidean(p1, p2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31.016124838541646"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dst"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "#### Question 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### GRADED\n",
    "### This exercise will use Euclidean distances.  \n",
    "### Please find the Euclidean distance between the points (1,2,3,-4,6) and (10,2,32,-2,0)\n",
    "### Assign distance as number to ans1\n",
    "### YOUR ANSWER BELOW\n",
    "\n",
    "p1 = (1,2,3,-4,6)\n",
    "p2 = (10,2,32,-2,0)\n",
    "\n",
    "\n",
    "\n",
    "ans1 = 31.016124838541646"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "Question 6",
     "locked": true,
     "points": "5",
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "###\n",
    "### AUTOGRADER TEST - DO NOT REMOVE\n",
    "###\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "#### Question 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### GRADED\n",
    "### Code a function called \"euclid_dist\" \n",
    "\n",
    "### ACCEPT two inputs, points, represented as tuples in the format, (a1, b1,...n1), (a2, b2, ...n2).\n",
    "### RETURN the euclidean distance\n",
    "\n",
    "### Remember: \"**\" is the python operator for exponents.\n",
    "\n",
    "### YOUR ANSWER BELOW\n",
    "\n",
    "def euclid_dist(p1, p2):\n",
    "    \"\"\"\n",
    "    Calculate the Euclidian Distance between two points\n",
    "    \n",
    "    Positional Arguments:\n",
    "        p1 -- A tuple of n numbers\n",
    "        p2 -- A tuple of n numbers\n",
    "    \n",
    "    Example:\n",
    "        p1 = (5,5)\n",
    "        p2 = (0,0)\n",
    "        p3 = (5,6,7,8,9,10)\n",
    "        p4 = (1,2,3,4,5,6)\n",
    "        print(euclid_dist(p1,p2)) #--> 7.0710678118654755\n",
    "        print(euclid_dist(p3,p4)) #--> 9.797958971132712\n",
    "    \"\"\"\n",
    "    total = 0\n",
    "    for i in range(len(p1)):\n",
    "        total += (p2[i] - p1[i])**2\n",
    "#     print(total)   \n",
    "    answ = total**(1/2)  \n",
    "    \n",
    "    return answ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "Question 7",
     "locked": true,
     "points": "10",
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "###\n",
    "### AUTOGRADER TEST - DO NOT REMOVE\n",
    "###\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.0710678118654755\n",
      "9.797958971132712\n"
     ]
    }
   ],
   "source": [
    "p1 = (5,5)\n",
    "p2 = (0,0)\n",
    "p3 = (5,6,7,8,9,10)\n",
    "p4 = (1,2,3,4,5,6)\n",
    "print(euclid_dist(p1,p2)) #--> 7.0710678118654755\n",
    "print(euclid_dist(p3,p4)) #--> 9.797958971132712"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.spatial import distance\n",
    "\n",
    "dst = distance.euclidean(p1, p2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "#### Distances with `numpy`\n",
    "The above exercise is a simple check for understanding. However, in our eventual KNN function we will use `numpy` to more efficiently calculate distances with the following code : `np.linalg.norm(np.array(p1)-np.array(p2))`.  \n",
    "\n",
    "Thankfully because `Pandas` uses `Numpy` \"under the hood\" we will not have to cast to numpy arrays with `np.arry()` instead it will look like:  \n",
    "`np.linalg.norm(row1 - row1)`  \n",
    "\n",
    "Now that we can easily calculate the distances between any two points, we can start to build our function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "#### Question 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### GRADED\n",
    "### Code a function called \"all_distances\"\n",
    "### ACCEPT two inputs:\n",
    "### An observation from a data set.  e.g: har_train.iloc[50,:]\n",
    "### The full data set. e.g. har_train.\n",
    "\n",
    "### Create a <list> or numpy array of distances between:\n",
    "### ### that single point, and all points in the full dataset\n",
    "\n",
    "### RETURN the list of distances SORTED from smallest to largest.\n",
    "\n",
    "### Notes:\n",
    "### Use `np.linalg.norm()`, as described in above cell.\n",
    "### The smallest distance should be 0.\n",
    "\n",
    "### YOUR ANSWER BELOW\n",
    "\n",
    "\n",
    "def all_distances(test_point, data_set):\n",
    "    \"\"\"\n",
    "    Find and return a list of distances between the \"test_point\"\n",
    "    and all the points in \"data_set\", sorted from smallest to largest.\n",
    "    \n",
    "    Positional Arguments:\n",
    "        test_point -- a Pandas Series corresponding to a row in \"data_set\"\n",
    "        data_set -- a Pandas DataFrame\n",
    "    \n",
    "    Example:\n",
    "        test_point = har_train.iloc[50,:]\n",
    "        data_set = har_train\n",
    "        \n",
    "        print(all_distances(test_point, data_set)[:5])\n",
    "        #--> [0.0, 2.7970187358249854, 2.922792670143521, 2.966555149052483, 3.033982453218797]\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "### Create a <list> or numpy array of distances between:\n",
    "### ### that single point, and all points in the full dataset\n",
    "\n",
    "    distances = [np.linalg.norm(data_set.iloc[i,:] - test_point) for i in range(len(data_set))]\n",
    "\n",
    "### RETURN the list of distances SORTED from smallest to largest.\n",
    "    distances.sort()\n",
    "### Notes:\n",
    "### Use `np.linalg.norm()`, as described in above cell.\n",
    "### The smallest distance should be 0\n",
    "    return distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "Question 8",
     "locked": true,
     "points": "15",
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "###\n",
    "### AUTOGRADER TEST - DO NOT REMOVE\n",
    "###\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0, 2.7970187358249854, 2.922792670143521, 2.966555149052483, 3.033982453218797]\n"
     ]
    }
   ],
   "source": [
    "test_point = har_train.iloc[50,:]\n",
    "data_set = har_train\n",
    "\n",
    "# distances = [np.linalg.norm(data_set.iloc[i,:] - test_point) for i in range(len(data_set))]\n",
    "\n",
    "print(all_distances(test_point, data_set)[:5])\n",
    " #--> [0.0, 2.7970187358249854, 2.922792670143521, 2.966555149052483, 3.033982453218797]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "#### Question 9 \n",
    "\n",
    "Returning the value of a point and the label associated with that point:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true,
    "nbgrader": {
     "grade": false,
     "locked": false,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "### GRADED\n",
    "### Code a function called \"labels_of_smallest\"\n",
    "### ACCEPT three inputs:\n",
    "### 1&2: numpy arrays, corresponding to 1: a numeric column and 2: a label column.\n",
    "### ### The i-th member of the numeric column corresponds to the i-th member of the label column\n",
    "### 3: an integer (>0); n.\n",
    "\n",
    "### RETURN a list (or numpy array) of the n labels corresponding to \n",
    "### ### the n smallest values in the numeric column.\n",
    "### NOTE: Make sure the order of labels corresponds to the order of values.\n",
    "\n",
    "### Hint: The labels are found in har_train_labels or y\n",
    "### Hint: `pd.concat()` might be useful for this or subsequent exercisces  \n",
    "### YOUR ANSWER BELOW\n",
    "\n",
    "def labels_of_smallest(numeric, labels, n):\n",
    "    \n",
    "    \"\"\"\n",
    "    Return the n labels corresponding to the n smallest values in the \"numeric\"\n",
    "    numpy array.\n",
    "    \n",
    "    Positional Arguments:\n",
    "        numeric -- a numpy array of numbers\n",
    "        labels -- a numpy array of labels (string or numeric)\n",
    "            corresponding to the values in \"numeric\"\n",
    "        n -- a positive integer\n",
    "        \n",
    "    Example:\n",
    "        numeric = np.array([7,6,5,4,3,2,1])\n",
    "        labels = np.array([\"a\",\"a\",\"b\",\"b\",\"b\",\"a\",\"a\"])\n",
    "        n = 6\n",
    "        \n",
    "        print(labels_of_smallest(numeric, labels, n))\n",
    "        #--> np.array(['a', 'a', 'b', 'b', 'b', 'a'])\n",
    "    \"\"\"\n",
    "    \n",
    "### ACCEPT three inputs:\n",
    "### 1&2: numpy arrays, corresponding to 1: a numeric column and 2: a label column.\n",
    "### ### The i-th member of the numeric column corresponds to the i-th member of the label column\n",
    "### 3: an integer (>0); n.\n",
    "\n",
    "### RETURN a list (or numpy array) of the n labels corresponding to \n",
    "### ### the n smallest values in the numeric column.\n",
    "### NOTE: Make sure the order of labels corresponds to the order of values.\n",
    "\n",
    "    zipped = list(zip(numeric, labels))\n",
    "    sort_zip = sorted(zipped, key = lambda x: x[0])\n",
    "\n",
    "### Hint: The labels are found in har_train_labels or y\n",
    "### Hint: `pd.concat()` might be useful for this or subsequent exercisces  \n",
    "    return [item[1] for item in sort_zip[:n]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "Question 9",
     "locked": true,
     "points": "15",
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "###\n",
    "### AUTOGRADER TEST - DO NOT REMOVE\n",
    "###\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a', 'a', 'b', 'b', 'b', 'a']\n"
     ]
    }
   ],
   "source": [
    " numeric = np.array([7,6,5,4,3,2,1])\n",
    "labels = np.array([\"a\",\"a\",\"b\",\"b\",\"b\",\"a\",\"a\"])\n",
    "n = 6\n",
    "        \n",
    "print(labels_of_smallest(numeric, labels, n))\n",
    " #--> np.array(['a', 'a', 'b', 'b', 'b', 'a'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "#### Question 10: \n",
    "Voting.\n",
    "Hint: look at [Counter](https://docs.python.org/3/library/collections.html#collections.Counter) and `.most_common()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### GRADED\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "### Build a function called \"label_voting\"\n",
    "### ACCEPT a non-empty numpy array of labels as input\n",
    "### RETURN the value that appears most frequently in that array\n",
    "### In the case of of a tie, RETURN the value in the tie that appears first in the array\n",
    "\n",
    "\n",
    "### YOUR ANSWER BELOW\n",
    "\n",
    "def label_voting(labels):\n",
    "    \"\"\"\n",
    "    Given a numpy array of labels. Return the label that appears most frequently\n",
    "    If there is a tie for most frequent, return the label that appears first.\n",
    "    \n",
    "    Positional Argument:\n",
    "        labels -- a numpy array of labels\n",
    "    \n",
    "    Example:\n",
    "        lab1 = np.array([1,2,2,3,3])\n",
    "        lab2 = np.array([\"a\",\"a\",\"b\",\"b\",\"b\"])\n",
    "        \n",
    "        print(label_voting(lab1)) #--> 2\n",
    "        print(label_voting(lab2)) #--> \"b\"\n",
    "        \n",
    "    \"\"\"\n",
    "    \n",
    "    return Counter(labels).most_common(1)[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "Question 10",
     "locked": true,
     "points": "15",
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "###\n",
    "### AUTOGRADER TEST - DO NOT REMOVE\n",
    "###\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "b\n"
     ]
    }
   ],
   "source": [
    "lab1 = np.array([1,2,2,3,3])\n",
    "lab2 = np.array([\"a\",\"a\",\"b\",\"b\",\"b\"])\n",
    "        \n",
    "print(label_voting(lab1)) #--> 2\n",
    "print(label_voting(lab2)) #--> \"b\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "#### Question 11\n",
    "Time to put everything together.  \n",
    "\n",
    "Question 6/7/8 involved calculating distances.\n",
    "Question 9 involved sorting and returning n labels.\n",
    "Question 10 counted \"votes.\"\n",
    "\n",
    "The next question asks for a KNN modeling function:  \n",
    "\n",
    "Given four inputs: \n",
    "1. a single value from  X_test (created above in our `test_train_split`)  \n",
    "2. X_train  \n",
    "3. y_train (labels)   \n",
    "4. n - the number of nearest neighbors to poll in making predictions.\n",
    "\n",
    "Create a function that:\n",
    "1. Calculates the Euclidean distance between that X_test-point and every point in X_train\n",
    "2. Finds the labels from the \"n\" nearest neighbors (ordered from closest to furthest)\n",
    "3. Returns a prediction according to the voting rules outlined above (simple majority - tie goes to closest/first)  \n",
    "\n",
    "Assign to \"`custom_KNN`\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### GRADED\n",
    "### Follow directions above\n",
    "### YOUR ANSWER BELOW\n",
    "\n",
    "def custom_KNN( point, X_train, y_train, n):\n",
    "    \"\"\"\n",
    "    Predict the label for a single point, given training data and a specified\n",
    "    \"n\" number of neighbors.\n",
    "    \n",
    "    Positional Arguments:\n",
    "        point -- a pandas Series corresponding to an observation of a point with\n",
    "             unknown label.\n",
    "        x_train -- a pandas DataFrame corresponding to the measurements\n",
    "            of points in a dataset. Assume all values are numeric, and\n",
    "            observations are in the rows; features in the columns\n",
    "        y_train -- a pandas Series corresponding to the labels for the observations\n",
    "            in x_train\n",
    "    \n",
    "    Example:\n",
    "        point = pd.Series([1,2])\n",
    "        X_train = pd.DataFrame([[1,2],[3,4],[5,6]])\n",
    "        y_train = pd.Series([\"a\",\"a\",\"b\"])\n",
    "        n = 2\n",
    "        print(custom_KNN(point, X_train, y_train, n)) #--> 'a'\n",
    "    \"\"\"\n",
    "# Create a function that:\n",
    "\n",
    "# 1). Calculates the Euclidean distance between that X_test-point and every point in X_train\n",
    "    distances = [np.linalg.norm(X_train.iloc[i,:] - point) for i in range(len(X_train))]\n",
    "\n",
    "# 2). Finds the labels from the \"n\" nearest neighbors (ordered from closest to furthest)\n",
    "    labels = labels_of_smallest(distances, y_train, n)\n",
    "\n",
    "# 3). Returns a prediction according to the voting rules outlined above (simple majority - tie goes to closest/first)    \n",
    "    closest = label_voting(labels)\n",
    "    \n",
    "    return closest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "Question 11",
     "locked": true,
     "points": "5",
     "solution": false
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "###\n",
    "### AUTOGRADER TEST - DO NOT REMOVE\n",
    "###\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a\n"
     ]
    }
   ],
   "source": [
    "point = pd.Series([1,2])\n",
    "X_train = pd.DataFrame([[1,2],[3,4],[5,6]])\n",
    "y_train = pd.Series([\"a\",\"a\",\"b\"])\n",
    "n = 2\n",
    "print(custom_KNN(point, X_train, y_train, n)) #--> 'a'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.0, 2.8284271247461903, 5.656854249492381]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distances = all_distances(point, X_train)\n",
    "distances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "You should now have a functioning KNN classifier assigned to the function `customKNN`.\n",
    "\n",
    "Let's now see how good our classifier is using `n` = 5.  \n",
    "\n",
    "Be warned, the below cell may or may not complete runing on Vocareum due to processing constraints.  (The cell took 12.9s on my machine, using my fairly efficient function, a less efficient function took ~5.5mins).  \n",
    "\n",
    "**FOR FASTER GRADING, TRY COMMENTING OUT THE CELL BELOW**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": false,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total 'test' observations: 2206\n",
      "Classifying every point in X_test would take too long - classify the first 200\n",
      "0\n",
      "100\n",
      "CPU times: user 3min 59s, sys: 36 ms, total: 3min 59s\n",
      "Wall time: 3min 59s\n"
     ]
    }
   ],
   "source": [
    "# %%time\n",
    "\n",
    "# # Create New tts\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.3, random_state=24)\n",
    "\n",
    "# print(\"Total 'test' observations:\", len(X_test))\n",
    "# print(\"Classifying every point in X_test would take too long - classify the first 200\")\n",
    "# custom_preds = []\n",
    "# for i, idx in enumerate(X_test.index[:200]):\n",
    "#     if i % 100 == 0: print(i)\n",
    "#     pred = custom_KNN(X_test.loc[idx,:], X_train, y_train, 5)\n",
    "#     custom_preds.append(pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "<a id = \"sklearn\"></a>\n",
    "### KNN in Sklearn\n",
    "\n",
    "While useful to see exactly how predictions are made using K-Nearest Neighbors, the `sklearn` has an implementation called [KNeighborsClassifier](http://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html) that will run much faster than our home-built version.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sklearn prediction performance\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       1.00      1.00      1.00        44\n",
      "           2       0.97      1.00      0.99        33\n",
      "           3       1.00      0.95      0.98        22\n",
      "           4       0.82      0.92      0.87        25\n",
      "           5       0.94      0.86      0.90        36\n",
      "           6       1.00      1.00      1.00        40\n",
      "\n",
      "   micro avg       0.96      0.96      0.96       200\n",
      "   macro avg       0.96      0.96      0.95       200\n",
      "weighted avg       0.96      0.96      0.96       200\n",
      "\n",
      "\n",
      "Home-Built prediction performance\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00        44\n",
      "           2       0.00      0.00      0.00        33\n",
      "           3       0.00      0.00      0.00        22\n",
      "           4       0.12      1.00      0.22        25\n",
      "           5       0.00      0.00      0.00        36\n",
      "           6       0.00      0.00      0.00        40\n",
      "\n",
      "   micro avg       0.12      0.12      0.12       200\n",
      "   macro avg       0.02      0.17      0.04       200\n",
      "weighted avg       0.02      0.12      0.03       200\n",
      "\n",
      "Total Differences: 172\n",
      "CPU times: user 796 ms, sys: 16 ms, total: 812 ms\n",
      "Wall time: 815 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Import\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Instantiate classifier\n",
    "# NB: Default distance is Euclidean\n",
    "knn = KNeighborsClassifier(n_neighbors = 5)\n",
    "\n",
    "# Fit model with training data\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "# Create predictions for first 200 test observations\n",
    "# # (As was done above with customKNN)\n",
    "skpreds = knn.predict(X_test[:200])\n",
    "\n",
    "print(\"sklearn prediction performance\")\n",
    "print(classification_report(y_test[:200], skpreds))\n",
    "\n",
    "\n",
    "### The below lines of code will compare the performance of your home-built classification with\n",
    "### The sklearn predictions -- if all the cells above were run sucessfully, you should see identical scores\n",
    "\n",
    "print(\"\\nHome-Built prediction performance\")\n",
    "print(classification_report(y_test[:200], custom_preds))\n",
    "\n",
    "\n",
    "### The below lines of code will explicitly compare predictions:\n",
    "### \"differences\" should == 0!\n",
    "\n",
    "### NB: Commenting/uncommenting multiple lines in Jupyter can be accomplished with:\n",
    "### <ctrl-/> on windows and <cmd-/> on mac\n",
    "differences = 0\n",
    "for cust, sk in zip(custom_preds, skpreds):\n",
    "    if cust != sk:\n",
    "        differences +=1\n",
    "print(\"Total Differences:\", differences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "#### Practice with `sklearn`:  \n",
    "\n",
    "The below questions will ask you to create a new test/train split, and fit a new KNN model with `sklearn`.  \n",
    "\n",
    "All of these steps have already been performed above. Feel free to reference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Ensure Data is consistent\n",
    "\n",
    "# read feature names\n",
    "feats = pd.read_table(FEATURE_NAMES, sep='\\n', header=None)\n",
    "\n",
    "# read in training data\n",
    "har_train = pd.read_table(TRAIN_DATA, sep='\\s+', header=None)\n",
    "\n",
    "# read in training labels, and clean them.\n",
    "har_train_labels = pd.read_table(TRAIN_LABELS, sep='\\n', header=None)\n",
    "clean_features = [feat[0].split(' ')[1] for feat in feats.values]\n",
    "har_train.columns = clean_features\n",
    "\n",
    "har_train_labels = pd.read_table(TRAIN_LABELS, sep='\\n', header=None)\n",
    "har_train_labels.columns = ['label']\n",
    "y = har_train_labels.loc[:, 'label']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "#### Question 12\n",
    "Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### GRADED\n",
    "### Making a new test-train-split on our data:\n",
    "### ### labels found in \"y\" and observations in `har_train`\n",
    "### ### For split, specify - test_size of .4 and a random_state of 1738.\n",
    "### assign output from the split to X_train2, X_test2, y_train2, y_test2 -- take care, the \"X\"s are capitlaized\n",
    "### and the \"y\"s are lower-case.\n",
    "### Which of the following would accomplish that task?\n",
    "\n",
    "### 'a') X_train2, X_test2, y_train2, y_test2 = train_test_split(har_train, y, test_size = .4, random_state = 1738)\n",
    "### 'b') X_train2, X_test2, y_train2, y_test2 = train_test_split(har_train, y, train_size = .4, random_state = 1738)\n",
    "### 'c') X_train2, X_test2, y_train2, y_test2 = train_test_split(har_train, y, .4, 1738)\n",
    "### 'd') X_train2, X_test2, y_train2, y_test2 = train_test_split(har_train, y, t_size = .4, rs = 1738)\n",
    "\n",
    "### Assign character associated with you choice as string to ans1\n",
    "### YOUR ANSWER BELOW\n",
    "\n",
    "ans1 = 'a'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "Question 12",
     "locked": true,
     "points": "10",
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "###\n",
    "### AUTOGRADER TEST - DO NOT REMOVE\n",
    "###\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "#### Question 13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "### This cell creates X_train3, X_test3, y_train3, and y_test3; used below.\n",
    "\n",
    "X_train3, X_test3, y_train3, y_test3 = train_test_split(har_train, y, test_size = .4, random_state = 2001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### GRADED\n",
    "### Build a KNN classifier using sklearn.\n",
    "### ### specify n_neighbors as 10. Otherwise accept the `KNeighborsClassifier` defaults.\n",
    "\n",
    "### Fit the model using the provided \"X_train3\" and \"y_train3\" variables, from above cell.\n",
    "### assign the predictions from your model for the provided \"X_test3\" data to a variable called ans1.\n",
    "### YOUR ANSWER BELOW\n",
    "\"\"\"\n",
    "Example:\n",
    "\n",
    "# Code for Instantiating a KNN Model\n",
    "\n",
    "# Fit KNN with X_train3 and y_train3\n",
    "\n",
    "# Create Predictions on X_test3\n",
    "\n",
    "ans1 = preds\n",
    "\n",
    "print(ans1[:5])\n",
    "#-->np.array([6 5 1 6 4])\n",
    "\n",
    "### NOTE: Your predictions may look different due to how \"random_state\" depends on current time.\n",
    "\"\"\"\n",
    "### Build a KNN classifier using sklearn.\n",
    "### ### specify n_neighbors as 10. Otherwise accept the `KNeighborsClassifier` defaults.\n",
    "\n",
    "# Instantiate classifier\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors = 10)\n",
    "\n",
    "### Fit the model using the provided \"X_train3\" and \"y_train3\" variables, from above cell.\n",
    "\n",
    "knn.fit(X_train3, y_train3)\n",
    "\n",
    "### assign the predictions from your model for the provided \"X_test3\" data to a variable called ans1.\n",
    "\n",
    "ans1 = knn.predict(X_test3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "Question 13",
     "locked": true,
     "points": "10",
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "###\n",
    "### AUTOGRADER TEST - DO NOT REMOVE\n",
    "###\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6 5 1 6 4]\n"
     ]
    }
   ],
   "source": [
    "print(ans1[:5])\n",
    "#-->np.array([6 5 1 6 4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "Building a model using sklearn is just as easy as those last two steps! As long as your data is in the right format, once you make your train/test split, the syntax for fitting pretty much any of the models in `sklearn` is about the same.   \n",
    "\n",
    "<a id=\"part3\"></a>\n",
    "## Part 3: Interpret Results\n",
    "\n",
    "For interpreting results we will be looking at the tradeoff between bias and variance as we change our `n_neighbors`. In many cases, false negatives are more costly and false positives. As such we will be looking primarily at the change in recall as we build a number of different models.  \n",
    "\n",
    "Note: The below takes some time to run. ~ 3.5min. Thus output is provided as screenshot below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# %%time\n",
    "# from sklearn.metrics import recall_score\n",
    "\n",
    "### Calculating Recal scores for multiple \"n-neighbors\"\n",
    "# recall_scores = {}\n",
    "# for n in [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,20,25,50,75,100]:\n",
    "#     knn = KNeighborsClassifier(n_neighbors=n)\n",
    "#     knn.fit(X_train, y_train)\n",
    "#     recall_scores[n] = recall_score(y_test, knn.predict(X_test), average = None)\n",
    "    \n",
    "### Put recall scores into DataFrame\n",
    "# scores_df = pd.DataFrame(recall_scores).T\n",
    "# scores_df.columns = [str(i) for i in range(1,7)]\n",
    "# scores_df.index = scores_df.index.astype(str)\n",
    "\n",
    "### Create plot of recall scores\n",
    "# plt.figure(figsize = (10,10))\n",
    "# for col in scores_df:\n",
    "#     if col != 'n_neighbors':\n",
    "#         plt.plot(scores_df[col], label = col)\n",
    "    \n",
    "# plt.ylabel(\" Recall Score\", fontsize = 12)\n",
    "# plt.xlabel(\"n_neighbors (NB: not an interval scale)\", fontsize = 12)\n",
    "# plt.legend(title = \"activity\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "#### Output\n",
    "![recall](./assets/recall.PNG)  \n",
    "\n",
    "#### Question 14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### GRADED\n",
    "### Looking at the recall scores above;\n",
    "### as n_neighbors trends towards 100 do we see in increase in:\n",
    "\n",
    "### 'a') bias\n",
    "### 'b') variance\n",
    "\n",
    "### Assign the string associated with your choice to ans1\n",
    "### YOUR ANSWER BELOW\n",
    "\n",
    "ans1 = 'a'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "Question 14",
     "locked": true,
     "points": "5",
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "###\n",
    "### AUTOGRADER TEST - DO NOT REMOVE\n",
    "###\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "#### Question 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": true,
    "nbgrader": {
     "grade": false,
     "locked": false,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "### GRADED\n",
    "### In looking at the recall scores above, does it look like the bestter KNN models have:\n",
    "\n",
    "### 'a') n_neighbors >= 15\n",
    "### 'b') n_neigbors < 15\n",
    "\n",
    "### Assign the string associated with your shoice to ans1\n",
    "### YOUR ANSWER BELOW\n",
    "\n",
    "ans1 = 'b'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "Question 15",
     "locked": true,
     "points": "5",
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "###\n",
    "### AUTOGRADER TEST - DO NOT REMOVE\n",
    "###\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "#### Question 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### GRADED\n",
    "### What might explain the ups-and-downs of recall in activities 4 and 6?\n",
    "\n",
    "### 'a') calculation of Euclidean Distance\n",
    "### 'b') Use of Entropy (information gain) for splitting\n",
    "### 'c') tie-breaking/voting proceedures\n",
    "### 'd') Simply a feature of KNN models: unavoidable\n",
    "### Assign the string associated with your choice to ans1\n",
    "\n",
    "### YOUR ANSWER BELOW\n",
    "\n",
    "ans1 = 'c'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "Question 16",
     "locked": true,
     "points": "5",
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "###\n",
    "### AUTOGRADER TEST - DO NOT REMOVE\n",
    "###\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "For this investigation of our model, recall was used. In other instances other metrics might be more useful, or more translatable to your use-case.  \n",
    "\n",
    "Hopefully from this brief look into tuning our model and investigating the effects it has become clear that either \"success\" or \"failure\" might be due to circumstance.  \n",
    "\n",
    "Even in the search for the trade-off between bias and variance, a single observation or even a pair of observations might not tell the full story."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 [3.6]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
