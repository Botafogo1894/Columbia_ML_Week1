{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "# Logistic Regression  \n",
    "\n",
    "---------------\n",
    "\n",
    "_Authors: Khal Makhoul, W.P.G.Peterson_   \n",
    "\n",
    "## Project Guide\n",
    "------------\n",
    "- [Project Overview](#overview)\n",
    "- [Introduction and Review](#intro)\n",
    "- [Data Exploration](#data)\n",
    "- [Coding Logistic Regression](#code)\n",
    "- [Logistic Regression in `sklearn`](#sklearn)\n",
    "\n",
    "<a id = \"overview\"></a>\n",
    "## Project Overview  \n",
    "-------------\n",
    "#### EXPECTED TIME 3 HRS\n",
    "\n",
    "This assignment will work through the definition of a Logistic Regression function in `Python`. After a summary of the equations that will be used, and a brief EDA of the \"Titanic\" data we will be using, you will be asked to define a number of functions which will, in sum, create a Logistic Regression.  \n",
    "A demonstration of `sklearn`'s implementation of Logistic Regression will close the assignment.\n",
    "\n",
    "\n",
    "You will be asked to code functions to do the following:\n",
    "1. Implement the Logistic Regression Algorithm\n",
    "    - Calculate the value of the sigmoid function\n",
    "    - Calculate the gradient of the log-likelihood with respect to $w$\n",
    "    - Sum the gradients of the log-likelihood with respect to $w$\n",
    "2. Execute logistic regression, stopping after a particular iteration\n",
    "3. Determine convergence of the logistic regression algorithm\n",
    "\n",
    "**Motivation**: Logistic Regression offers a way to to create a fairly interpretable parametic model for binary classification.\n",
    "\n",
    "**Problem**: Using Logistic Regression, predict whether or not a passenger survived the sinking of the Titanic.\n",
    "\n",
    "**Data**: The data for today comes from [Kaggle's Titanic Data](https://www.kaggle.com/c/titanic/data)  \n",
    "\n",
    "Please see above link for a more complete description of the data.\n",
    "\n",
    "**Grading**: NOTE, THE FINAL TWO CELLS IN THIS NOTEBOOK WILL CAUSE GRADING TO RUN SLOWLY. IF YOU WANT TO SPEED UP THE GRADING PROCESS, KEEP CODE IN THE LAST TWO CELLS COMMENTED OUT.\n",
    "\n",
    "<a id = \"intro\"></a>\n",
    "\n",
    "### Introduction and Review\n",
    "\n",
    "The lectures this week derived all of the equations that used in this assignment.  \n",
    "\n",
    "Recall that the likelihood for Logistic Regression is given by:\n",
    "\n",
    "$$p(y_1,\\ ...,\\ y_n\\ |\\ x_1,\\ ...,\\ x_n,\\ w)\\ =\\prod\\limits_{i=1}^n\\ \\sigma_i(y_i \\cdot w)$$  \n",
    "\n",
    "For coding purposes, we need the expression for the gradient of the log-likelihood with respect to $w$:\n",
    "\n",
    "\n",
    "$$\\nabla_w \\mathcal{L} = \\sum_{i = 1}^n (1 − \\sigma_i(y_i \\cdot w))\\ y_i x_i$$  \n",
    "\n",
    "Where: $$\\sigma_i(y_i \\cdot w) = \\frac{e^{y_iX_i^Tw}}{1+e^{y_ix_i^Tw}}$$  \n",
    "\n",
    "\n",
    "<a id = \"data\"></a>\n",
    "### Data Exploration\n",
    "\n",
    "This assignment will analyze data from the Titanic passenger manifest. Demographic and trip information for each passenger is coupled with whether or not they survived the disaster.\n",
    "\n",
    "Start by examining the data as usual:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Moran, Mr. James</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>330877</td>\n",
       "      <td>8.4583</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>McCarthy, Mr. Timothy J</td>\n",
       "      <td>male</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>17463</td>\n",
       "      <td>51.8625</td>\n",
       "      <td>E46</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "5            6         0       3   \n",
       "6            7         0       1   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "5                                   Moran, Mr. James    male   NaN      0   \n",
       "6                            McCarthy, Mr. Timothy J    male  54.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  \n",
       "5      0            330877   8.4583   NaN        Q  \n",
       "6      0             17463  51.8625   E46        S  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import the necessary modules and sets a few plotting parameters for display\n",
    "\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "plt.rcParams['figure.figsize'] = (20.0, 10.0)\n",
    "\n",
    "# Load the data into a `pandas` DataFrame object\n",
    "tr_path = '../resource/asnlib/publicdata/train.csv'\n",
    "titanic_df = pd.read_csv(tr_path)\n",
    "\n",
    "# Examine head of df\n",
    "titanic_df.head(7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "#### Question 1\n",
    "Dropping nulls.  \n",
    "\n",
    "The exercise below requires dropping certain records / columns.  \n",
    "\n",
    "The general rules followed below are:  \n",
    "\n",
    "- If a column consists mostly of missing data, that column probably will not be of much use in prediction.  \n",
    "- If a column has very few missing values, and enough records to build a model are complete, the records with missing values in that column may be cast out.  \n",
    "\n",
    "The question statement below includes specific directions as to how to implement the above rules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true,
    "nbgrader": {
     "grade": false,
     "grade_id": "shape",
     "locked": false,
     "points": "5",
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "### GRADED\n",
    "\n",
    "### 1. Drop all of the columns in `titanic_df` which are filled more than 50% with nulls.\n",
    "### 2. If a column has fewer than 10 missing values:\n",
    "### ### Drop all of the records with missing data in that column.\n",
    "\n",
    "### After performing the above drops, what is the shape of the DataFrame?\n",
    "### Assign ints to `row` and `cols` below corresponding to the *remaining* number of rows / columns\n",
    "\n",
    "### YOUR ANSWER BELOW\n",
    "\n",
    "rows = 889\n",
    "cols = 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Moran, Mr. James</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>330877</td>\n",
       "      <td>8.4583</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>McCarthy, Mr. Timothy J</td>\n",
       "      <td>male</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>17463</td>\n",
       "      <td>51.8625</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Palsson, Master. Gosta Leonard</td>\n",
       "      <td>male</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>349909</td>\n",
       "      <td>21.0750</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Johnson, Mrs. Oscar W (Elisabeth Vilhelmina Berg)</td>\n",
       "      <td>female</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>347742</td>\n",
       "      <td>11.1333</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Nasser, Mrs. Nicholas (Adele Achem)</td>\n",
       "      <td>female</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>237736</td>\n",
       "      <td>30.0708</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Sandstrom, Miss. Marguerite Rut</td>\n",
       "      <td>female</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>PP 9549</td>\n",
       "      <td>16.7000</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Bonnell, Miss. Elizabeth</td>\n",
       "      <td>female</td>\n",
       "      <td>58.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>113783</td>\n",
       "      <td>26.5500</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Saundercock, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5. 2151</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Andersson, Mr. Anders Johan</td>\n",
       "      <td>male</td>\n",
       "      <td>39.0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>347082</td>\n",
       "      <td>31.2750</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Vestrom, Miss. Hulda Amanda Adolfina</td>\n",
       "      <td>female</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>350406</td>\n",
       "      <td>7.8542</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Hewlett, Mrs. (Mary D Kingcome)</td>\n",
       "      <td>female</td>\n",
       "      <td>55.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>248706</td>\n",
       "      <td>16.0000</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Rice, Master. Eugene</td>\n",
       "      <td>male</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>382652</td>\n",
       "      <td>29.1250</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Williams, Mr. Charles Eugene</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>244373</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Vander Planke, Mrs. Julius (Emelia Maria Vande...</td>\n",
       "      <td>female</td>\n",
       "      <td>31.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>345763</td>\n",
       "      <td>18.0000</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Masselmani, Mrs. Fatima</td>\n",
       "      <td>female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2649</td>\n",
       "      <td>7.2250</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Fynney, Mr. Joseph J</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>239865</td>\n",
       "      <td>26.0000</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Beesley, Mr. Lawrence</td>\n",
       "      <td>male</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>248698</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>McGowan, Miss. Anna \"Annie\"</td>\n",
       "      <td>female</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>330923</td>\n",
       "      <td>8.0292</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Sloper, Mr. William Thompson</td>\n",
       "      <td>male</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>113788</td>\n",
       "      <td>35.5000</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Palsson, Miss. Torborg Danira</td>\n",
       "      <td>female</td>\n",
       "      <td>8.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>349909</td>\n",
       "      <td>21.0750</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Asplund, Mrs. Carl Oscar (Selma Augusta Emilia...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>347077</td>\n",
       "      <td>31.3875</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Emir, Mr. Farred Chehab</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2631</td>\n",
       "      <td>7.2250</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Fortune, Mr. Charles Alexander</td>\n",
       "      <td>male</td>\n",
       "      <td>19.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>19950</td>\n",
       "      <td>263.0000</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>29</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>O'Dwyer, Miss. Ellen \"Nellie\"</td>\n",
       "      <td>female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>330959</td>\n",
       "      <td>7.8792</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Todoroff, Mr. Lalio</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>349216</td>\n",
       "      <td>7.8958</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>861</th>\n",
       "      <td>862</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Giles, Mr. Frederick Edward</td>\n",
       "      <td>male</td>\n",
       "      <td>21.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>28134</td>\n",
       "      <td>11.5000</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>862</th>\n",
       "      <td>863</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Swift, Mrs. Frederick Joel (Margaret Welles Ba...</td>\n",
       "      <td>female</td>\n",
       "      <td>48.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>17466</td>\n",
       "      <td>25.9292</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>863</th>\n",
       "      <td>864</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Sage, Miss. Dorothy Edith \"Dolly\"</td>\n",
       "      <td>female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>CA. 2343</td>\n",
       "      <td>69.5500</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>864</th>\n",
       "      <td>865</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Gill, Mr. John William</td>\n",
       "      <td>male</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>233866</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>865</th>\n",
       "      <td>866</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Bystrom, Mrs. (Karolina)</td>\n",
       "      <td>female</td>\n",
       "      <td>42.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>236852</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>866</th>\n",
       "      <td>867</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Duran y More, Miss. Asuncion</td>\n",
       "      <td>female</td>\n",
       "      <td>27.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>SC/PARIS 2149</td>\n",
       "      <td>13.8583</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>867</th>\n",
       "      <td>868</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Roebling, Mr. Washington Augustus II</td>\n",
       "      <td>male</td>\n",
       "      <td>31.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17590</td>\n",
       "      <td>50.4958</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>868</th>\n",
       "      <td>869</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>van Melkebeke, Mr. Philemon</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>345777</td>\n",
       "      <td>9.5000</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>869</th>\n",
       "      <td>870</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Johnson, Master. Harold Theodor</td>\n",
       "      <td>male</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>347742</td>\n",
       "      <td>11.1333</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>870</th>\n",
       "      <td>871</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Balkic, Mr. Cerin</td>\n",
       "      <td>male</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>349248</td>\n",
       "      <td>7.8958</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>871</th>\n",
       "      <td>872</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Beckwith, Mrs. Richard Leonard (Sallie Monypeny)</td>\n",
       "      <td>female</td>\n",
       "      <td>47.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>11751</td>\n",
       "      <td>52.5542</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>872</th>\n",
       "      <td>873</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Carlsson, Mr. Frans Olof</td>\n",
       "      <td>male</td>\n",
       "      <td>33.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>695</td>\n",
       "      <td>5.0000</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>873</th>\n",
       "      <td>874</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Vander Cruyssen, Mr. Victor</td>\n",
       "      <td>male</td>\n",
       "      <td>47.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>345765</td>\n",
       "      <td>9.0000</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>874</th>\n",
       "      <td>875</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Abelson, Mrs. Samuel (Hannah Wizosky)</td>\n",
       "      <td>female</td>\n",
       "      <td>28.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>P/PP 3381</td>\n",
       "      <td>24.0000</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>875</th>\n",
       "      <td>876</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Najib, Miss. Adele Kiamie \"Jane\"</td>\n",
       "      <td>female</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2667</td>\n",
       "      <td>7.2250</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>876</th>\n",
       "      <td>877</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Gustafsson, Mr. Alfred Ossian</td>\n",
       "      <td>male</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7534</td>\n",
       "      <td>9.8458</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>877</th>\n",
       "      <td>878</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Petroff, Mr. Nedelio</td>\n",
       "      <td>male</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>349212</td>\n",
       "      <td>7.8958</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>878</th>\n",
       "      <td>879</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Laleff, Mr. Kristo</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>349217</td>\n",
       "      <td>7.8958</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>879</th>\n",
       "      <td>880</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Potter, Mrs. Thomas Jr (Lily Alexenia Wilson)</td>\n",
       "      <td>female</td>\n",
       "      <td>56.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>11767</td>\n",
       "      <td>83.1583</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>880</th>\n",
       "      <td>881</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Shelley, Mrs. William (Imanita Parrish Hall)</td>\n",
       "      <td>female</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>230433</td>\n",
       "      <td>26.0000</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>881</th>\n",
       "      <td>882</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Markun, Mr. Johann</td>\n",
       "      <td>male</td>\n",
       "      <td>33.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>349257</td>\n",
       "      <td>7.8958</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>882</th>\n",
       "      <td>883</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Dahlberg, Miss. Gerda Ulrika</td>\n",
       "      <td>female</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7552</td>\n",
       "      <td>10.5167</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>883</th>\n",
       "      <td>884</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Banfield, Mr. Frederick James</td>\n",
       "      <td>male</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>C.A./SOTON 34068</td>\n",
       "      <td>10.5000</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>884</th>\n",
       "      <td>885</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Sutehall, Mr. Henry Jr</td>\n",
       "      <td>male</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>SOTON/OQ 392076</td>\n",
       "      <td>7.0500</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>885</th>\n",
       "      <td>886</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Rice, Mrs. William (Margaret Norton)</td>\n",
       "      <td>female</td>\n",
       "      <td>39.0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>382652</td>\n",
       "      <td>29.1250</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>887</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Montvila, Rev. Juozas</td>\n",
       "      <td>male</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>211536</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>888</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Graham, Miss. Margaret Edith</td>\n",
       "      <td>female</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>112053</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>889</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Johnston, Miss. Catherine Helen \"Carrie\"</td>\n",
       "      <td>female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>W./C. 6607</td>\n",
       "      <td>23.4500</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>890</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Behr, Mr. Karl Howell</td>\n",
       "      <td>male</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>111369</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>891</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Dooley, Mr. Patrick</td>\n",
       "      <td>male</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>370376</td>\n",
       "      <td>7.7500</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>891 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId  Survived  Pclass  \\\n",
       "0              1         0       3   \n",
       "1              2         1       1   \n",
       "2              3         1       3   \n",
       "3              4         1       1   \n",
       "4              5         0       3   \n",
       "5              6         0       3   \n",
       "6              7         0       1   \n",
       "7              8         0       3   \n",
       "8              9         1       3   \n",
       "9             10         1       2   \n",
       "10            11         1       3   \n",
       "11            12         1       1   \n",
       "12            13         0       3   \n",
       "13            14         0       3   \n",
       "14            15         0       3   \n",
       "15            16         1       2   \n",
       "16            17         0       3   \n",
       "17            18         1       2   \n",
       "18            19         0       3   \n",
       "19            20         1       3   \n",
       "20            21         0       2   \n",
       "21            22         1       2   \n",
       "22            23         1       3   \n",
       "23            24         1       1   \n",
       "24            25         0       3   \n",
       "25            26         1       3   \n",
       "26            27         0       3   \n",
       "27            28         0       1   \n",
       "28            29         1       3   \n",
       "29            30         0       3   \n",
       "..           ...       ...     ...   \n",
       "861          862         0       2   \n",
       "862          863         1       1   \n",
       "863          864         0       3   \n",
       "864          865         0       2   \n",
       "865          866         1       2   \n",
       "866          867         1       2   \n",
       "867          868         0       1   \n",
       "868          869         0       3   \n",
       "869          870         1       3   \n",
       "870          871         0       3   \n",
       "871          872         1       1   \n",
       "872          873         0       1   \n",
       "873          874         0       3   \n",
       "874          875         1       2   \n",
       "875          876         1       3   \n",
       "876          877         0       3   \n",
       "877          878         0       3   \n",
       "878          879         0       3   \n",
       "879          880         1       1   \n",
       "880          881         1       2   \n",
       "881          882         0       3   \n",
       "882          883         0       3   \n",
       "883          884         0       2   \n",
       "884          885         0       3   \n",
       "885          886         0       3   \n",
       "886          887         0       2   \n",
       "887          888         1       1   \n",
       "888          889         0       3   \n",
       "889          890         1       1   \n",
       "890          891         0       3   \n",
       "\n",
       "                                                  Name     Sex   Age  SibSp  \\\n",
       "0                              Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1    Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                               Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3         Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                             Allen, Mr. William Henry    male  35.0      0   \n",
       "5                                     Moran, Mr. James    male   NaN      0   \n",
       "6                              McCarthy, Mr. Timothy J    male  54.0      0   \n",
       "7                       Palsson, Master. Gosta Leonard    male   2.0      3   \n",
       "8    Johnson, Mrs. Oscar W (Elisabeth Vilhelmina Berg)  female  27.0      0   \n",
       "9                  Nasser, Mrs. Nicholas (Adele Achem)  female  14.0      1   \n",
       "10                     Sandstrom, Miss. Marguerite Rut  female   4.0      1   \n",
       "11                            Bonnell, Miss. Elizabeth  female  58.0      0   \n",
       "12                      Saundercock, Mr. William Henry    male  20.0      0   \n",
       "13                         Andersson, Mr. Anders Johan    male  39.0      1   \n",
       "14                Vestrom, Miss. Hulda Amanda Adolfina  female  14.0      0   \n",
       "15                    Hewlett, Mrs. (Mary D Kingcome)   female  55.0      0   \n",
       "16                                Rice, Master. Eugene    male   2.0      4   \n",
       "17                        Williams, Mr. Charles Eugene    male   NaN      0   \n",
       "18   Vander Planke, Mrs. Julius (Emelia Maria Vande...  female  31.0      1   \n",
       "19                             Masselmani, Mrs. Fatima  female   NaN      0   \n",
       "20                                Fynney, Mr. Joseph J    male  35.0      0   \n",
       "21                               Beesley, Mr. Lawrence    male  34.0      0   \n",
       "22                         McGowan, Miss. Anna \"Annie\"  female  15.0      0   \n",
       "23                        Sloper, Mr. William Thompson    male  28.0      0   \n",
       "24                       Palsson, Miss. Torborg Danira  female   8.0      3   \n",
       "25   Asplund, Mrs. Carl Oscar (Selma Augusta Emilia...  female  38.0      1   \n",
       "26                             Emir, Mr. Farred Chehab    male   NaN      0   \n",
       "27                      Fortune, Mr. Charles Alexander    male  19.0      3   \n",
       "28                       O'Dwyer, Miss. Ellen \"Nellie\"  female   NaN      0   \n",
       "29                                 Todoroff, Mr. Lalio    male   NaN      0   \n",
       "..                                                 ...     ...   ...    ...   \n",
       "861                        Giles, Mr. Frederick Edward    male  21.0      1   \n",
       "862  Swift, Mrs. Frederick Joel (Margaret Welles Ba...  female  48.0      0   \n",
       "863                  Sage, Miss. Dorothy Edith \"Dolly\"  female   NaN      8   \n",
       "864                             Gill, Mr. John William    male  24.0      0   \n",
       "865                           Bystrom, Mrs. (Karolina)  female  42.0      0   \n",
       "866                       Duran y More, Miss. Asuncion  female  27.0      1   \n",
       "867               Roebling, Mr. Washington Augustus II    male  31.0      0   \n",
       "868                        van Melkebeke, Mr. Philemon    male   NaN      0   \n",
       "869                    Johnson, Master. Harold Theodor    male   4.0      1   \n",
       "870                                  Balkic, Mr. Cerin    male  26.0      0   \n",
       "871   Beckwith, Mrs. Richard Leonard (Sallie Monypeny)  female  47.0      1   \n",
       "872                           Carlsson, Mr. Frans Olof    male  33.0      0   \n",
       "873                        Vander Cruyssen, Mr. Victor    male  47.0      0   \n",
       "874              Abelson, Mrs. Samuel (Hannah Wizosky)  female  28.0      1   \n",
       "875                   Najib, Miss. Adele Kiamie \"Jane\"  female  15.0      0   \n",
       "876                      Gustafsson, Mr. Alfred Ossian    male  20.0      0   \n",
       "877                               Petroff, Mr. Nedelio    male  19.0      0   \n",
       "878                                 Laleff, Mr. Kristo    male   NaN      0   \n",
       "879      Potter, Mrs. Thomas Jr (Lily Alexenia Wilson)  female  56.0      0   \n",
       "880       Shelley, Mrs. William (Imanita Parrish Hall)  female  25.0      0   \n",
       "881                                 Markun, Mr. Johann    male  33.0      0   \n",
       "882                       Dahlberg, Miss. Gerda Ulrika  female  22.0      0   \n",
       "883                      Banfield, Mr. Frederick James    male  28.0      0   \n",
       "884                             Sutehall, Mr. Henry Jr    male  25.0      0   \n",
       "885               Rice, Mrs. William (Margaret Norton)  female  39.0      0   \n",
       "886                              Montvila, Rev. Juozas    male  27.0      0   \n",
       "887                       Graham, Miss. Margaret Edith  female  19.0      0   \n",
       "888           Johnston, Miss. Catherine Helen \"Carrie\"  female   NaN      1   \n",
       "889                              Behr, Mr. Karl Howell    male  26.0      0   \n",
       "890                                Dooley, Mr. Patrick    male  32.0      0   \n",
       "\n",
       "     Parch            Ticket      Fare Embarked  \n",
       "0        0         A/5 21171    7.2500        S  \n",
       "1        0          PC 17599   71.2833        C  \n",
       "2        0  STON/O2. 3101282    7.9250        S  \n",
       "3        0            113803   53.1000        S  \n",
       "4        0            373450    8.0500        S  \n",
       "5        0            330877    8.4583        Q  \n",
       "6        0             17463   51.8625        S  \n",
       "7        1            349909   21.0750        S  \n",
       "8        2            347742   11.1333        S  \n",
       "9        0            237736   30.0708        C  \n",
       "10       1           PP 9549   16.7000        S  \n",
       "11       0            113783   26.5500        S  \n",
       "12       0         A/5. 2151    8.0500        S  \n",
       "13       5            347082   31.2750        S  \n",
       "14       0            350406    7.8542        S  \n",
       "15       0            248706   16.0000        S  \n",
       "16       1            382652   29.1250        Q  \n",
       "17       0            244373   13.0000        S  \n",
       "18       0            345763   18.0000        S  \n",
       "19       0              2649    7.2250        C  \n",
       "20       0            239865   26.0000        S  \n",
       "21       0            248698   13.0000        S  \n",
       "22       0            330923    8.0292        Q  \n",
       "23       0            113788   35.5000        S  \n",
       "24       1            349909   21.0750        S  \n",
       "25       5            347077   31.3875        S  \n",
       "26       0              2631    7.2250        C  \n",
       "27       2             19950  263.0000        S  \n",
       "28       0            330959    7.8792        Q  \n",
       "29       0            349216    7.8958        S  \n",
       "..     ...               ...       ...      ...  \n",
       "861      0             28134   11.5000        S  \n",
       "862      0             17466   25.9292        S  \n",
       "863      2          CA. 2343   69.5500        S  \n",
       "864      0            233866   13.0000        S  \n",
       "865      0            236852   13.0000        S  \n",
       "866      0     SC/PARIS 2149   13.8583        C  \n",
       "867      0          PC 17590   50.4958        S  \n",
       "868      0            345777    9.5000        S  \n",
       "869      1            347742   11.1333        S  \n",
       "870      0            349248    7.8958        S  \n",
       "871      1             11751   52.5542        S  \n",
       "872      0               695    5.0000        S  \n",
       "873      0            345765    9.0000        S  \n",
       "874      0         P/PP 3381   24.0000        C  \n",
       "875      0              2667    7.2250        C  \n",
       "876      0              7534    9.8458        S  \n",
       "877      0            349212    7.8958        S  \n",
       "878      0            349217    7.8958        S  \n",
       "879      1             11767   83.1583        C  \n",
       "880      1            230433   26.0000        S  \n",
       "881      0            349257    7.8958        S  \n",
       "882      0              7552   10.5167        S  \n",
       "883      0  C.A./SOTON 34068   10.5000        S  \n",
       "884      0   SOTON/OQ 392076    7.0500        S  \n",
       "885      5            382652   29.1250        Q  \n",
       "886      0            211536   13.0000        S  \n",
       "887      0            112053   30.0000        S  \n",
       "888      2        W./C. 6607   23.4500        S  \n",
       "889      0            111369   30.0000        C  \n",
       "890      0            370376    7.7500        Q  \n",
       "\n",
       "[891 rows x 11 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic_df.drop(['Cabin'], axis =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_df = titanic_df.dropna(subset=['Embarked'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "Question 1",
     "locked": true,
     "points": "5",
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "###\n",
    "### AUTOGRADER TEST - DO NOT REMOVE\n",
    "###\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId      0\n",
       "Survived         0\n",
       "Pclass           0\n",
       "Name             0\n",
       "Sex              0\n",
       "Age            177\n",
       "SibSp            0\n",
       "Parch            0\n",
       "Ticket           0\n",
       "Fare             0\n",
       "Cabin          687\n",
       "Embarked         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic_df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(889, 12)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "#### Question 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### GRADED\n",
    "### How many records are missing from the \"Age\" feature?\n",
    "\n",
    "### Assign int response to ans1\n",
    "### YOUR ANSWER BELOW\n",
    "\n",
    "ans1 = 177"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "Question 2",
     "locked": true,
     "points": "5",
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "###\n",
    "### AUTOGRADER TEST - DO NOT REMOVE\n",
    "###\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "Given the fairly large number of values missing from \"Age\", and the feature's likely relationship with survival, we will create an educated guess for missing passenger ages; imputing the ages using a $k$-Nearest-Neighbor algorithm.\n",
    "\n",
    "Note: In imputing values for \"age\",  \"`survival`\" will be excluded from the $X$ matrix since that is the value we ultimately plan to predict.\n",
    "\n",
    "#### KNeighborsRegressor in `sklearn`\n",
    "Because `sklearn` automatically converts all data to floats before fitting models, it is necessary to encode any and all categorical variables as dummy variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pclass     Sex   Age  SibSp  Parch     Fare Embarked\n",
       "0       3    male  22.0      1      0   7.2500        S\n",
       "1       1  female  38.0      1      0  71.2833        C\n",
       "2       3  female  26.0      0      0   7.9250        S\n",
       "3       1  female  35.0      1      0  53.1000        S\n",
       "4       3    male  35.0      0      0   8.0500        S"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Drop irrelevant categories\n",
    "titanic_df.drop(['Ticket','Cabin', 'PassengerId', 'Name'], axis=1, inplace=True)\n",
    "titanic_df = titanic_df.loc[titanic_df['Embarked'].notnull(),:]\n",
    "\n",
    "### Drop \"Survived\" for purposes of KNN imputation:\n",
    "y_target = titanic_df.Survived\n",
    "titanic_knn = titanic_df.drop(['Survived'], axis = 1)  \n",
    "titanic_knn.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Sex_male</th>\n",
       "      <th>Embarked_Q</th>\n",
       "      <th>Embarked_S</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pclass   Age  SibSp  Parch     Fare  Sex_male  Embarked_Q  Embarked_S\n",
       "0       3  22.0      1      0   7.2500         1           0           1\n",
       "1       1  38.0      1      0  71.2833         0           0           0\n",
       "2       3  26.0      0      0   7.9250         0           0           1\n",
       "3       1  35.0      1      0  53.1000         0           0           1\n",
       "4       3  35.0      0      0   8.0500         1           0           1"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Adding dummy variables for categorical vars\n",
    "to_dummy = ['Sex','Embarked']\n",
    "titanic_knn = pd.get_dummies(titanic_knn, prefix = to_dummy, columns = to_dummy, drop_first = True)\n",
    "\n",
    "titanic_knn.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data to Impute\n",
      "    Pclass  SibSp  Parch     Fare  Sex_male  Embarked_Q  Embarked_S\n",
      "5        3      0      0   8.4583         1           1           0\n",
      "17       2      0      0  13.0000         1           0           1\n",
      "19       3      0      0   7.2250         0           0           0\n",
      "\n",
      "Imputed Ages\n",
      "    Pclass  SibSp  Parch     Fare  Sex_male  Embarked_Q  Embarked_S   Age\n",
      "5        3      0      0   8.4583         1           1           0  47.2\n",
      "17       2      0      0  13.0000         1           0           1  25.6\n",
      "19       3      0      0   7.2250         0           0           0  23.0\n",
      "Shape with imputed values: (889, 8)\n",
      "Shape before imputation: (889, 8)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Sex_male</th>\n",
       "      <th>Embarked_Q</th>\n",
       "      <th>Embarked_S</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3</td>\n",
       "      <td>47.2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.4583</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>51.8625</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pclass   Age  SibSp  Parch     Fare  Sex_male  Embarked_Q  Embarked_S\n",
       "0       3  22.0      1      0   7.2500         1           0           1\n",
       "1       1  38.0      1      0  71.2833         0           0           0\n",
       "2       3  26.0      0      0   7.9250         0           0           1\n",
       "3       1  35.0      1      0  53.1000         0           0           1\n",
       "4       3  35.0      0      0   8.0500         1           0           1\n",
       "5       3  47.2      0      0   8.4583         1           1           0\n",
       "6       1  54.0      0      0  51.8625         1           0           1"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Splitting data - on whether or not \"Age\" is specified.\n",
    "\n",
    "# Training data -- \"Age\" Not null; \"Age\" as target\n",
    "train = titanic_knn[titanic_knn.Age.notnull()]\n",
    "X_train = train.drop(['Age'], axis = 1)\n",
    "y_train = train.Age\n",
    "\n",
    "\n",
    "# Data to impute, -- Where Age is null; Remove completely-null \"Age\" column.\n",
    "impute = titanic_knn[titanic_knn.Age.isnull()].drop(['Age'], axis = 1)\n",
    "print(\"Data to Impute\")\n",
    "print(impute.head(3))\n",
    "\n",
    "# import algorithm\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "# Instantiate\n",
    "knr = KNeighborsRegressor()\n",
    "\n",
    "# Fit\n",
    "knr.fit(X_train, y_train)\n",
    "\n",
    "# Create Predictions\n",
    "imputed_ages = knr.predict(impute)\n",
    "\n",
    "# Add to Df\n",
    "impute['Age'] = imputed_ages\n",
    "print(\"\\nImputed Ages\")\n",
    "print(impute.head(3))\n",
    "\n",
    "# Re-combine dataframes\n",
    "titanic_imputed = pd.concat([train, impute], sort = False, axis = 0)\n",
    "\n",
    "# Return to original order - to match back up with \"Survived\"\n",
    "titanic_imputed.sort_index(inplace = True)\n",
    "print(\"Shape with imputed values:\", titanic_imputed.shape)\n",
    "print(\"Shape before imputation:\", titanic_knn.shape)\n",
    "titanic_imputed.head(7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "It would be appropriate to spend more time taking care with the imputation of age. For brevity's sake that will not be done here.\n",
    "\n",
    "#### Brief EDA\n",
    "\n",
    "First Look at tabulations of categorical variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All Combos or categorical vars: \n",
      " [('Pclass', 'Sex'), ('Pclass', 'Embarked'), ('Sex', 'Embarked')] \n",
      "\n",
      "Row Percents: \n",
      " Sex       female      male\n",
      "Pclass                    \n",
      "1       0.429907  0.570093\n",
      "2       0.413043  0.586957\n",
      "3       0.293279  0.706721 \n",
      "\n",
      "Column Percents: \n",
      " Sex       female      male\n",
      "Pclass                    \n",
      "1       0.294872  0.211438\n",
      "2       0.243590  0.187175\n",
      "3       0.461538  0.601386 \n",
      "---------------\n",
      "\n",
      "Row Percents: \n",
      " Embarked         C         Q         S\n",
      "Pclass                                \n",
      "1         0.397196  0.009346  0.593458\n",
      "2         0.092391  0.016304  0.891304\n",
      "3         0.134420  0.146640  0.718941 \n",
      "\n",
      "Column Percents: \n",
      " Embarked         C         Q         S\n",
      "Pclass                                \n",
      "1         0.505952  0.025974  0.197205\n",
      "2         0.101190  0.038961  0.254658\n",
      "3         0.392857  0.935065  0.548137 \n",
      "---------------\n",
      "\n",
      "Row Percents: \n",
      " Embarked         C         Q         S\n",
      "Sex                                   \n",
      "female    0.233974  0.115385  0.650641\n",
      "male      0.164645  0.071057  0.764298 \n",
      "\n",
      "Column Percents: \n",
      " Embarked         C         Q         S\n",
      "Sex                                   \n",
      "female    0.434524  0.467532  0.315217\n",
      "male      0.565476  0.532468  0.684783 \n",
      "---------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "# Lists of categorical v. numeric features\n",
    "categorical = ['Pclass','Sex','Embarked']\n",
    "numeric = ['Age','SibSp','Parch','Fare']\n",
    "\n",
    "# Create all pairs of categorical variables, look at distributions\n",
    "cat_combos = list(itertools.combinations(categorical, 2))\n",
    "print(\"All Combos or categorical vars: \\n\",cat_combos, \"\\n\")\n",
    "for row, col in cat_combos:\n",
    "    print(\"Row Percents: \\n\",pd.crosstab(titanic_df[row], titanic_df[col], normalize=\"index\"), \"\\n\")\n",
    "    print(\"Column Percents: \\n\", pd.crosstab(titanic_df[row], titanic_df[col], normalize=\"columns\"),\"\\n---------------\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "**Correlation heatmap of the numberic variables**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x720 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "sns.heatmap(titanic_df[numeric].corr(), cmap = \"coolwarm\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "#### Question 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### GRADED\n",
    "### True or False:\n",
    "### Other than the autocorrelation,\n",
    "### Two of the above variables in the heatmap have a correlation definitively greater than 0.5 or less than -0.5?\n",
    "\n",
    "### Assign boolean answer to ans1\n",
    "### YOUR ANSWER BELOW\n",
    "\n",
    "ans1 = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "Question 3",
     "locked": true,
     "points": "2",
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "###\n",
    "### AUTOGRADER TEST - DO NOT REMOVE\n",
    "###\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "<a id = \"code\"></a>\n",
    "### Coding Logistic Regression\n",
    "\n",
    "The first function will perform the preprocessing of our data. The steps are:  \n",
    "\n",
    "**First**: Ensure that the x- and y- matricies have the observations as rows, and features as columns.  \n",
    "- The x-matrix will be n-rows and d-columns. Where $n>d$\n",
    "- The y-vector will be a 1-dimensional numpy array of length n.  \n",
    "\n",
    "**Second**: A column of ones must be added to the x-inputs matrix, increasing its dimensions to n-by-d+1.  \n",
    "\n",
    "**Third**: Ensure that the y-vector has all values encoded as 1 and -1, NOT 1 and 0.  \n",
    "\n",
    "**Fourth**: The initial vector of weights should be created, a vector of length d+1 of all 0's (Hint: look at `np.zeros`)\n",
    "\n",
    "Those three matricies should all be returned. e.g.:  \n",
    "\n",
    "`return prepared_x, prepared_y, initial_w`  \n",
    "\n",
    "See example below of returning multiple items with a single function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a: 1 b: 2 c: 3 z: (1, 2, 3)\n"
     ]
    }
   ],
   "source": [
    "def ex_func(): return 1,2,3\n",
    "\n",
    "\n",
    "z = ex_func()\n",
    "a,b,c = ex_func()\n",
    "\n",
    "print(\"a:\", a,\"b:\",b,\"c:\",c,\"z:\",z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "#### Question 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "### GRADED\n",
    "### Follow directions given above\n",
    "### YOUR ANSWER BELOW\n",
    "\n",
    "def prepare_data(input_x, target_y):\n",
    "    \"\"\"\n",
    "    Confirm dimensions of x and y, transpose if appropriate;\n",
    "    Add column of ones to x;\n",
    "    Ensure y consists of 1's and -1's;\n",
    "    Create weights array of all 0s\n",
    "    \n",
    "    Return X, y, and weights.\n",
    "    \n",
    "    Arguments:\n",
    "        input_x - a numpy array \n",
    "        target_y - a numpy array\n",
    "        \n",
    "    Returns:\n",
    "        prepared_x -- a 2-d numpy array; first column consists of 1's,\n",
    "            more rows than columns\n",
    "        prepared_y -- a numpy array consisting only of 1s and -1s\n",
    "        initial_w -- a 1-d numpy array consisting of \"d+1\" 0s, where\n",
    "            \"d+1\" is the number of columns in \"prepared_x\"\n",
    "        \n",
    "    Example:\n",
    "        x = np.array([[1,2,3,4],[11,12,13,14]])\n",
    "        y = np.array([1,0,1,1])\n",
    "        x,y,w = prepare_data(x,y)\n",
    "        \n",
    "        print(x) #--> array([[ 1,  1, 11],\n",
    "                            [ 1,  2, 12],\n",
    "                            [ 1,  3, 13],\n",
    "                            [ 1,  4, 14]])\n",
    "                            \n",
    "        print(y) #--> array([1, -1, 1, 1])\n",
    "        \n",
    "        print(w) #--> array([0., 0., 0.])\n",
    "        \n",
    "    Assumptions:\n",
    "        Assume that there are more observations than features in `input_x`\n",
    "    \"\"\"\n",
    "\n",
    "# First: Ensure that the x- and y- matricies have the observations as rows, and features as columns.\n",
    "    if input_x.shape[0] < input_x.shape[1]:\n",
    "        input_x = input_x.T\n",
    "\n",
    "# The x-matrix will be n-rows and d-columns. Where  n>dn>d \n",
    "# The y-vector will be a 1-dimensional numpy array of length n.\n",
    "    if len(target_y.shape) > 1:\n",
    "        if min(target_y.shape) == 1:\n",
    "            target_y.reshape(-1)\n",
    "# Second: A column of ones must be added to the x-inputs matrix, increasing its dimensions to n-by-d+1.\n",
    "\n",
    "    v = np.ones((input_x.shape[0], 1))\n",
    "    input_x = np.concatenate((v, input_x), axis = 1)\n",
    "# Third: Ensure that the y-vector has all values encoded as 1 and -1, NOT 1 and 0.\n",
    "\n",
    "    target_y = np.array([y if y == 1 else -1 for y in target_y])\n",
    "# Fourth: The initial vector of weights should be created, a vector of length d+1 of all 0's (Hint: look at np.zeros)\n",
    "\n",
    "    weights = np.zeros(input_x.shape[1])\n",
    "    \n",
    "#     Return X, y, and weights.\n",
    "    \n",
    "    return input_x, target_y, weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "Question 4",
     "locked": true,
     "points": "10",
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "###\n",
    "### AUTOGRADER TEST - DO NOT REMOVE\n",
    "###\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.  1. 11.]\n",
      " [ 1.  2. 12.]\n",
      " [ 1.  3. 13.]\n",
      " [ 1.  4. 14.]]\n",
      "[ 1 -1  1  1]\n",
      "[0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "x = np.array([[1,2,3,4],[11,12,13,14]])\n",
    "y = np.array([1,0,1,1])\n",
    "x,y,w = prepare_data(x,y)\n",
    "        \n",
    "print(x) #--> array([[ 1,  1, 11],\n",
    "                            \n",
    "print(y) #--> array([1, -1, 1, 1])\n",
    "        \n",
    "print(w) #--> array([0., 0., 0.])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0.])"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "#### Question 5\n",
    "The next function will calculate the value of the sigmoid. \n",
    "\n",
    "Equation for the sigmoid:  \n",
    "$$\\sigma_i(y_i \\cdot w) = \\frac{e^{y_iX_i^Tw}}{1+e^{y_ix_i^Tw}}$$  \n",
    "\n",
    "Define a function called `sigmoid_single`:\n",
    "\n",
    "**Given** $x_i$, $y_i$, and $w$  \n",
    "**Return** a float, between 0 and 1.  \n",
    "\n",
    "Hint: First calculate $e^{y_ix_i^Tw}$; use `np.exp()`.  \n",
    "\n",
    "Look closely at the examples below.  \n",
    "$e^{y_ix_i^Tw}$ will evaluate to $np.inf$ when $y_ix_i^Tw$ is greater than ~709.782. In this case, a `\"1\"` should be returned by the function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "### GRADED\n",
    "### Follow directions above\n",
    "### YOUR ANSWER BELOW\n",
    "def sigmoid_single(x, y, w):\n",
    "    \"\"\"\n",
    "    Obtain the value of a Sigmoid using training data.\n",
    "    \n",
    "    Arguments:\n",
    "        x - a vector of length d\n",
    "        y - either 1, or -1\n",
    "        w - a vector of length d\n",
    "    \n",
    "    Example:\n",
    "        x = np.array([23.0,75])\n",
    "        y = -1\n",
    "        w = np.array([2,-.5])\n",
    "        sig = sigmoid_single(x, y, w)\n",
    "        \n",
    "        print(sig) #--> 0.0002034269780552065\n",
    "        \n",
    "        x2 = np.array([ 1. , 22., 0. , 1. , 7.25 , 0. , 3. , 1. , 1.])\n",
    "        w2 = np.array([ -10.45 , -376.7215 , -0.85, -10.5 , 212.425475 , -1.1, -36.25 , -17.95 , -7.1])\n",
    "        y2 = -1\n",
    "        sig2 = sigmoid_single(x2,y2,w2)\n",
    "        \n",
    "        print(sig2) #--> 1\n",
    "    \"\"\"\n",
    "# Given  xixi ,  yiyi , and  ww \n",
    "# Return a float, between 0 and 1.\n",
    "\n",
    "# Hint: First calculate  eyixTiweyixiTw ; use np.exp().\n",
    "\n",
    "    expo = y*np.matmul(x.T, w)\n",
    "# Look closely at the examples below.\n",
    "# eyixTiweyixiTw  will evaluate to  np.infnp.inf  when  yixTiwyixiTw  is greater than ~709.782. \n",
    "    if expo > 709.782:\n",
    "        return 1\n",
    "    else:\n",
    "        return np.exp(expo) / (1 + np.exp(expo))\n",
    "\n",
    "# In this case, a \"1\" should be returned by the function.\n",
    "\n",
    "    return float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "Question 5",
     "locked": true,
     "points": "15",
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "###\n",
    "### AUTOGRADER TEST - DO NOT REMOVE\n",
    "###\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0002034269780552065\n",
      "1\n"
     ]
    }
   ],
   "source": [
    " x = np.array([23.0,75])\n",
    "y = -1\n",
    "w = np.array([2,-.5])\n",
    "sig = sigmoid_single(x, y, w)\n",
    "        \n",
    "print(sig) #--> 0.0002034269780552065\n",
    "        \n",
    "x2 = np.array([ 1. , 22., 0. , 1. , 7.25 , 0. , 3. , 1. , 1.])\n",
    "w2 = np.array([ -10.45 , -376.7215 , -0.85, -10.5 , 212.425475 , -1.1, -36.25 , -17.95 , -7.1])\n",
    "y2 = -1\n",
    "\n",
    "sig2 = sigmoid_single(x2,y2,w2)\n",
    "        \n",
    "print(sig2) #--> 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "#### Question 6\n",
    "With the sigmoid, $\\sigma_i(y_i \\cdot w)$ defined above, we will tackle the rest of the function that is summed to calculate the gradient of the log-likelihood.   \n",
    "\n",
    "In a function named `to_sum`:  \n",
    "\n",
    "\n",
    "**Given** $x_i$, $y_i$, and $w$  \n",
    "**Return** $(1-\\sigma_i(y_i\\cdot w))y_ix_i$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### GRADED\n",
    "### YOUR ANSWER BELOW\n",
    "def to_sum(x,y,w):\n",
    "    \"\"\"\n",
    "    Obtain the value of the function that will eventually be summed to \n",
    "    find the gradient of the log-likelihood.\n",
    "    \n",
    "    Arguments:\n",
    "        x - a vector of length d\n",
    "        y - either 1, or -1\n",
    "        w - a vector of length d\n",
    "        \n",
    "    Example:\n",
    "        x = np.array([23.0,75])\n",
    "        y = -1\n",
    "        w = np.array([.1,-.2])\n",
    "        print(to_sum(x,y,w)) # --> array([-7.01756737e-05, -2.28833719e-04])\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "#     Obtain the value of the function that will eventually be summed to \n",
    "#     find the gradient of the log-likelihood.\n",
    "\n",
    "\n",
    "    \n",
    "    return (1 - sigmoid_single(x, y, w))*y*x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "Question 6",
     "locked": true,
     "points": "15",
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "###\n",
    "### AUTOGRADER TEST - DO NOT REMOVE\n",
    "###\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-7.01756737e-05 -2.28833719e-04]\n"
     ]
    }
   ],
   "source": [
    "x = np.array([23.0,75])\n",
    "y = -1\n",
    "w = np.array([.1,-.2])\n",
    "print(to_sum(x,y,w)) # --> array([-7.01756737e-05, -2.28833719e-04])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "#### Question 7\n",
    "Finally, code a function called `sum_all`:    \n",
    "\n",
    "\n",
    "**Given**: The pre-processed matricies corresponding to X, y, and weights  \n",
    "**Return**: $\\sum_{i = 1}^n (1 − \\sigma_i(y_i \\cdot w))\\ y_i x_i$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### GRADED\n",
    "### Follow instructions above\n",
    "### YOUR ANSWER BELOW\n",
    "def sum_all(x_input, y_target, w):\n",
    "    \"\"\"\n",
    "    Obtain and return the gradient of the log-likelihood\n",
    "    \n",
    "    Arguments:\n",
    "        x_input - *preprocessed* an array of shape n-by-d\n",
    "        y_target - *preprocessed* a vector of length n\n",
    "        w - a vector of length d\n",
    "        \n",
    "    Example:\n",
    "        x = np.array([[1,22,7.25],[1,38,71.2833]])\n",
    "        y = np.array([-1,1])\n",
    "        w = np.array([.1,-.2, .5])\n",
    "        print(sum_all(x,y,w)) #--> array([-0.33737816, -7.42231958, -2.44599168])\n",
    "        \n",
    "    \"\"\"\n",
    "# Obtain and return the gradient of the log-likelihood\n",
    "    zipped = list(zip(x_input, y_target))\n",
    "       \n",
    "    return sum([to_sum(x, y, w) for x, y in zipped])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "Question 7",
     "locked": true,
     "points": "25",
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "###\n",
    "### AUTOGRADER TEST - DO NOT REMOVE\n",
    "###\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.33737816 -7.42231958 -2.44599168]\n"
     ]
    }
   ],
   "source": [
    "x = np.array([[1,22,7.25],[1,38,71.2833]])\n",
    "y = np.array([-1,1])\n",
    "w = np.array([.1,-.2, .5])\n",
    "print(sum_all(x,y,w)) #--> array([-0.33737816, -7.42231958, -2.44599168])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "#### Question 8\n",
    "Code a function called `update_w`, that performs a single-step of gradient descent for calculating the Logistic Regression weights:\n",
    "\n",
    "**Given**: Pre-processed matricies of x, and y; the current weights - $w_i$, and \"$\\eta$\"  \n",
    "**Return**: $w_{i+1}$ Which is equal to: $w_i + \\eta \\sum_{i = 1}^n (1 − \\sigma_i(y_i \\cdot w_i))\\ y_i x_i$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### GRADED\n",
    "### YOUR ANSWER BELOW\n",
    "def update_w(x_input, y_target, w, eta):\n",
    "    \"\"\"Obtain and return updated Logistic Regression weights\n",
    "    \n",
    "    Arguments:\n",
    "        x_input - *preprocessed* an array of shape n-by-d\n",
    "        y_target - *preprocessed* a vector of length n\n",
    "        w - a vector of length d\n",
    "        eta - a float, positive, close to 0\n",
    "        \n",
    "    Example:\n",
    "        x = np.array([[1,22,7.25],[1,38,71.2833]])\n",
    "        y = np.array([-1,1])\n",
    "        w = np.array([.1,-.2, .5])\n",
    "        eta = .1\n",
    "        \n",
    "        print(update_w(x,y,w, eta)) #--> array([ 0.06626218, -0.94223196,  0.25540083])\n",
    "\"\"\"\n",
    "    \n",
    "    return w + eta*sum_all(x_input, y_target, w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "Question 8",
     "locked": true,
     "points": "25",
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "###\n",
    "### AUTOGRADER TEST - DO NOT REMOVE\n",
    "###\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.06626218 -0.94223196  0.25540083]\n"
     ]
    }
   ],
   "source": [
    "x = np.array([[1,22,7.25],[1,38,71.2833]])\n",
    "y = np.array([-1,1])\n",
    "w = np.array([.1,-.2, .5])\n",
    "eta = .1\n",
    "        \n",
    "print(update_w(x,y,w, eta)) #--> array([ 0.06626218, -0.94223196,  0.25540083])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "#### Question 9\n",
    "Next, create a function called `fixed_iteration` which will perform gradient descent, calculating Logistic Regression weights for a specified number of steps.  \n",
    "\n",
    "\n",
    "**Given**: *Un-preprocessed* x- and y- matricies, an $\\eta$ parameter that is positive and close to 0, and an integer number of steps  \n",
    "**Return**: $w_{steps}$ where $w_{i+1} = w_i + \\eta \\sum_{i = 1}^n (1 − \\sigma_i(y_i \\cdot w_i))\\ y_i x_i$  \n",
    "\n",
    "NB: Initial weights ($w_0$) should all be 0's like are returned from the `prepare_data` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### GRADED\n",
    "### Follow directions above\n",
    "### YOUR ANSWER BELOW\n",
    "\n",
    "def fixed_iteration(x_input, y_target, eta, steps):\n",
    "    \n",
    "    \"\"\"\n",
    "    Return weights calculated from 'steps' number of steps of gradient descent.\n",
    "    \n",
    "    Arguments:\n",
    "        x_input - *NOT-preprocessed* an array\n",
    "        y_target - *NOT-preprocessed* a vector of length n\n",
    "        eta - a float, positve, close to 0\n",
    "        steps - an int\n",
    "        \n",
    "    Example:\n",
    "        x = np.array([[22,7.25],[38,71.2833],[26,7.925],[35,53.1]])\n",
    "        y = np.array([-1,1,1,1])\n",
    "        eta = .1\n",
    "        steps = 100\n",
    "        \n",
    "        print(fixed_iteration(x,y, eta, steps)) #--> np.array([-0.9742495,  -0.41389924, 6.8199374 ])\n",
    "    \n",
    "    \"\"\"\n",
    "# Preprocess data with first function\n",
    "    input_x, target_y, weights = prepare_data(x_input, y_target)\n",
    "    \n",
    "#iterate over number of steps and update weights\n",
    "\n",
    "    for i in range(steps):\n",
    "        weights = update_w(input_x, target_y, weights, eta)\n",
    "        \n",
    "    return weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "Question 9",
     "locked": true,
     "points": "15",
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "###\n",
    "### AUTOGRADER TEST - DO NOT REMOVE\n",
    "###\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.9742495  -0.41389924  6.8199374 ]\n"
     ]
    }
   ],
   "source": [
    "x = np.array([[22,7.25],[38,71.2833],[26,7.925],[35,53.1]])\n",
    "y = np.array([-1,1,1,1])\n",
    "eta = .1\n",
    "steps = 100\n",
    "        \n",
    "print(fixed_iteration(x,y, eta, steps)) #--> np.array([-0.9742495,  -0.41389924, 6.8199374 ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "#### Question 10\n",
    "For the final function, a  prediction will be created for out-of-sample data.  \n",
    "\n",
    "Code a function called \"`predict`\".\n",
    "\n",
    "Accept two inputs:  \n",
    "- An **un-preprocessed** observation of X -- a vector as numpy array  \n",
    "- A numpy array of weights\n",
    "\n",
    "Return:\n",
    "A label prediction for the x observations; either -1 or 1 (integers).  \n",
    "\n",
    "**NB:**\n",
    "FIRST preprocess X. Then;  \n",
    "If $X^T\\cdot w > 0$  predict 1. Otherwise, predict -1.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### GRADED\n",
    "### Follow Directions Above\n",
    "### YOUR ANSWER BELOW\n",
    "def predict(x_input, weights):\n",
    "    \"\"\"\n",
    "    Return the label prediction, 1 or -1 (an integer), for the given x_input and LR weights.\n",
    "    \n",
    "    Arguments:\n",
    "        x_input - *NOT-preprocessed* a vector of length d-1\n",
    "        weights - a vector of length d\n",
    "               \n",
    "    Example:\n",
    "        Xs = np.array([[22,7.25],[38,71.2833],[26,7.925],[35,53.1]])\n",
    "        weights = np.array([0,1,-1])\n",
    "        \n",
    "        for X in Xs:\n",
    "            print(predict(X,weights))\n",
    "            #-->     1\n",
    "                    -1\n",
    "                     1\n",
    "                    -1\n",
    "    \"\"\"\n",
    "\n",
    "# NB: FIRST preprocess X. Then;\n",
    "\n",
    "    input_x = np.insert(x_input, 0 ,1)\n",
    "\n",
    "\n",
    "# If  XT⋅w>0XT⋅w>0  predict 1. Otherwise, predict -1.\n",
    "\n",
    "    if np.matmul(input_x.T, weights) > 0:\n",
    "        return 1\n",
    "    else:\n",
    "        return -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "Question 10",
     "locked": true,
     "points": "15",
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "###\n",
    "### AUTOGRADER TEST - DO NOT REMOVE\n",
    "###\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "-1\n",
      "1\n",
      "-1\n"
     ]
    }
   ],
   "source": [
    "Xs = np.array([[22,7.25],[38,71.2833],[26,7.925],[35,53.1]])\n",
    "weights = np.array([0,1,-1])\n",
    "        \n",
    "for X in Xs:\n",
    "    print(predict(X,weights))\n",
    "#                     1\n",
    "#                     -1\n",
    "#                      1\n",
    "#                     -1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "<a id = \"sklearn\"></a>\n",
    "### Logistic Regression in `sklearn`\n",
    "\n",
    "The following cells will demonstrate Logistic Regression using `sklearn`, and compare the custom Logistic Regression build in the previous functions to `sklearn's`\n",
    "\n",
    "[Logistic Regression in `sklearn` - Documentation](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4.07454344]\n",
      "[[-0.88163966 -0.03085442 -0.29522778 -0.07714244  0.00431432 -2.40900805\n",
      "   0.08754702 -0.21682852]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "lr = LogisticRegression()\n",
    "\n",
    "lr.fit(titanic_imputed, y_target)\n",
    "\n",
    "# Create sklearn's predictions\n",
    "sk_pred = lr.predict(titanic_imputed)\n",
    "\n",
    "print(lr.intercept_)\n",
    "print(lr.coef_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "If the above functions are correctly defined, the below cell should work\n",
    "While the particular coeffcients will be very different (regularization is implemented in the `sklearn` instantiation), at least the signs should mostly be the same.  \n",
    "\n",
    "**FOR FASTER GRADING TRY COMMENTING OUT THE BELOW CELLS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "nbgrader": {
     "grade": false,
     "locked": false,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# %%time\n",
    "# # This cell may take awhile\n",
    "# wt = fixed_iteration(titanic_imputed.values, y_target.values, .05, 12000)\n",
    "\n",
    "# print(wt)\n",
    "\n",
    "# cust_preds = np.array([predict(x,wt) for x in titanic_imputed.values])\n",
    "# cust_preds[cust_preds == -1] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "nbgrader": {
     "grade": false,
     "locked": false,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# print(\"sklearn:\")\n",
    "# print(classification_report(y_target, sk_pred))\n",
    "\n",
    "# print(\"Custom:\")\n",
    "# print(classification_report(y_target, cust_preds))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 [3.6]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
